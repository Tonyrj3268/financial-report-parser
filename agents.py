import PyPDF2
import base64
import io
from typing import Optional, List, Dict, Any, Tuple
from google import genai
import os
from pydantic import BaseModel, Field
import json
from dotenv import load_dotenv

# å°å…¥æ¨¡å‹
from src.models.cash_equivalents import CashAndEquivalents, cash_equivalents_prompt
from src.models.prepayments import PrePayments, prepayments_prompt
from src.models.receivables_related_parties import (
    ReceivablesRelatedParties,
    receivables_related_parties_prompt,
)
from src.models.total_liabilities import TotalLiabilities, total_liabilities_prompt

load_dotenv()

class ProcessingResults(BaseModel):
    """è™•ç†çµæœçµ±è¨ˆ"""

    token_usage: List[int] = Field(default_factory=list, description="Tokenä½¿ç”¨çµ±è¨ˆ")
    model_results: Dict[str, Any] = Field(default_factory=dict, description="æ¨¡å‹çµæœ")
    total_tokens: int = Field(default=0, description="ç¸½tokenæ•¸")


# å…¨åŸŸçµæœçµ±è¨ˆ
processing_stats = ProcessingResults()


def record_token_usage(step_name: str, response):
    """è¨˜éŒ„tokenä½¿ç”¨é‡"""
    try:
        if hasattr(response, "usage_metadata"):
            usage = response.usage_metadata
            input_tokens = getattr(usage, "prompt_token_count", 0)
            output_tokens = getattr(usage, "candidates_token_count", 0)
            total_tokens = input_tokens + output_tokens

            processing_stats.token_usage.append(total_tokens)
            processing_stats.total_tokens += total_tokens

            print(
                f"ğŸ“Š {step_name} - Tokenä½¿ç”¨: è¼¸å…¥={input_tokens}, è¼¸å‡º={output_tokens}, ç¸½è¨ˆ={total_tokens}"
            )
        else:
            print(f"âš ï¸ {step_name} - ç„¡æ³•ç²å–tokenä½¿ç”¨è³‡è¨Š")
    except Exception as e:
        print(f"âŒ è¨˜éŒ„tokenä½¿ç”¨æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")


def display_model_result(model_name: str, result: Any):
    """é¡¯ç¤ºæ¨¡å‹çµæœçš„è©³ç´°å…§å®¹"""
    print(f"\nğŸ“‹ {model_name} è©³ç´°çµæœ:")
    print("=" * 50)

    if result is None:
        print("âŒ ç„¡çµæœ")
        return

    try:
        # å°‡Pydanticæ¨¡å‹è½‰æ›ç‚ºå­—å…¸
        if hasattr(result, "model_dump"):
            result_dict = result.model_dump()
        elif hasattr(result, "dict"):
            result_dict = result.dict()
        else:
            result_dict = result

        # æ ¼å¼åŒ–é¡¯ç¤º
        def format_value(key, value, indent=0):
            prefix = "  " * indent

            if isinstance(value, dict):
                print(f"{prefix}{key}:")
                for sub_key, sub_value in value.items():
                    format_value(sub_key, sub_value, indent + 1)
            elif isinstance(value, list):
                print(f"{prefix}{key}: {value}")
            elif key == "value" and isinstance(value, (int, float)):
                # æ ¼å¼åŒ–æ•¸å€¼é¡¯ç¤º
                formatted_value = (
                    f"{value:,.2f}" if isinstance(value, float) else f"{value:,}"
                )
                print(f"{prefix}{key}: {formatted_value}")
            else:
                print(f"{prefix}{key}: {value}")

        for key, value in result_dict.items():
            format_value(key, value)

    except Exception as e:
        print(f"âŒ é¡¯ç¤ºçµæœæ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
        print(f"åŸå§‹çµæœ: {result}")


def display_final_summary():
    """é¡¯ç¤ºæœ€çµ‚çµ±è¨ˆæ‘˜è¦"""
    print("\n" + "=" * 80)
    print("ğŸ¯ æœ€çµ‚è™•ç†æ‘˜è¦")
    print("=" * 80)

    # Tokenä½¿ç”¨çµ±è¨ˆ
    print(f"\nğŸ’° Tokenä½¿ç”¨çµ±è¨ˆ:")
    print(f"ç¸½Tokenæ•¸: {processing_stats.total_tokens:,}")

    # æ¨¡å‹çµæœçµ±è¨ˆ
    print(f"\nğŸ“ˆ æ¨¡å‹è™•ç†çµæœ:")
    successful_models = 0
    failed_models = 0

    for model_name, result in processing_stats.model_results.items():
        if result is not None:
            print(f"  âœ… {model_name}: æˆåŠŸ")
            successful_models += 1
        else:
            print(f"  âŒ {model_name}: å¤±æ•—")
            failed_models += 1

    print(f"\nğŸ“‹ è™•ç†çµ±è¨ˆ:")
    print(f"  æˆåŠŸæ¨¡å‹: {successful_models}")
    print(f"  å¤±æ•—æ¨¡å‹: {failed_models}")
    print(
        f"  æˆåŠŸç‡: {(successful_models/(successful_models+failed_models)*100):.1f}%"
        if (successful_models + failed_models) > 0
        else "N/A"
    )

    print("=" * 80)


class FinancialStatementLocation(BaseModel):
    """è²¡å‹™å ±è¡¨é …ç›®ä½ç½®è³‡è¨Š"""

    item_name: str = Field(description="è²¡å‹™å ±è¡¨é …ç›®åç¨±")
    page_numbers: List[int] = Field(description="è©²é …ç›®æ‰€åœ¨çš„é æ•¸åˆ—è¡¨")
    found: bool = Field(description="æ˜¯å¦æ‰¾åˆ°è©²é …ç›®")
    notes: Optional[str] = Field(default=None, description="é¡å¤–å‚™è¨»")


class FinancialStatementsAnalysis(BaseModel):
    """è²¡å‹™å ±è¡¨åˆ†æçµæœ"""

    individual_balance_sheet: FinancialStatementLocation = Field(
        description="å€‹é«”è³‡ç”¢è² å‚µè¡¨"
    )
    individual_comprehensive_income: FinancialStatementLocation = Field(
        description="å€‹é«”ç¶œåˆæç›Šè¡¨"
    )
    individual_equity_changes: FinancialStatementLocation = Field(
        description="å€‹é«”æ¬Šç›Šè®Šå‹•è¡¨"
    )
    individual_cash_flow: FinancialStatementLocation = Field(
        description="å€‹é«”ç¾é‡‘æµé‡è¡¨"
    )
    important_accounting_items: FinancialStatementLocation = Field(
        description="é‡è¦æœƒè¨ˆé …ç›®æ˜ç´°è¡¨"
    )


class TableOfContentsInfo(BaseModel):
    """ç›®éŒ„é è³‡è¨Š"""

    has_toc: bool = Field(description="æ˜¯å¦æœ‰ç›®éŒ„é ")
    toc_page_numbers: Optional[List[int]] = Field(description="ç›®éŒ„é çš„é æ•¸åˆ—è¡¨")
    notes: Optional[str] = Field(default=None, description="é¡å¤–å‚™è¨»")

# è¨­å®šGemini API
def setup_gemini():
    """è¨­å®šGemini API"""
    # è«‹è¨­å®šæ‚¨çš„APIé‡‘é‘°
    api_key = os.getenv("GEMINI_API_KEY")  # å¾ç’°å¢ƒè®Šæ•¸è®€å–APIé‡‘é‘°
    if not api_key:
        print("è­¦å‘Š: è«‹è¨­å®šGEMINI_API_KEYç’°å¢ƒè®Šæ•¸")
        return None

    client = genai.Client(api_key=api_key)
    return client


def extract_first_ten_pages_to_base64(pdf_path: str) -> Optional[str]:
    """
    è®€å–PDFæª”æ¡ˆï¼Œæå–å‰åé ä¸¦è½‰æ›ç‚ºbase64ç·¨ç¢¼

    Args:
        pdf_path (str): PDFæª”æ¡ˆè·¯å¾‘

    Returns:
        Optional[str]: base64ç·¨ç¢¼çš„PDFå…§å®¹ï¼Œå¦‚æœå¤±æ•—å‰‡è¿”å›None
    """
    try:
        # è®€å–PDFæª”æ¡ˆ
        with open(pdf_path, "rb") as file:
            pdf_reader = PyPDF2.PdfReader(file)

            # å»ºç«‹æ–°çš„PDF writer
            pdf_writer = PyPDF2.PdfWriter()

            # å–å¾—ç¸½é æ•¸
            total_pages = len(pdf_reader.pages)
            pages_to_extract = min(5, total_pages)  # å–å‰5é æˆ–ç¸½é æ•¸ï¼ˆå¦‚æœå°‘æ–¼5é ï¼‰

            # æå–å‰åé 
            for page_num in range(pages_to_extract):
                page = pdf_reader.pages[page_num]
                pdf_writer.add_page(page)

            # å°‡æå–çš„é é¢å¯«å…¥è¨˜æ†¶é«”
            output_buffer = io.BytesIO()
            pdf_writer.write(output_buffer)

            # å–å¾—PDFçš„äºŒé€²åˆ¶è³‡æ–™
            pdf_bytes = output_buffer.getvalue()

            # è½‰æ›ç‚ºbase64ç·¨ç¢¼
            base64_encoded = base64.b64encode(pdf_bytes).decode("utf-8")

            print(f"æˆåŠŸæå–å‰ {pages_to_extract} é ä¸¦è½‰æ›ç‚ºbase64ç·¨ç¢¼")
            print(f"base64ç·¨ç¢¼é•·åº¦: {len(base64_encoded)} å­—å…ƒ")

            return base64_encoded

    except FileNotFoundError:
        print(f"éŒ¯èª¤: æ‰¾ä¸åˆ°æª”æ¡ˆ {pdf_path}")
        return None
    except Exception as e:
        print(f"è™•ç†PDFæ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
        return None


def find_table_of_contents_page(base64_pdf: str) -> Optional[TableOfContentsInfo]:
    """
    æ‰¾åˆ°PDFä¸­çš„ç›®éŒ„é ä½ç½®

    Args:
        base64_pdf (str): base64ç·¨ç¢¼çš„PDFå…§å®¹

    Returns:
        Optional[TableOfContentsInfo]: ç›®éŒ„é è³‡è¨Šï¼Œå¦‚æœå¤±æ•—å‰‡è¿”å›None
    """
    try:
        client = setup_gemini()
        if not client:
            return None

        prompt = """
        è«‹åˆ†æé€™å€‹PDFæ–‡ä»¶ï¼Œæ‰¾å‡ºç›®éŒ„é ï¼ˆTable of Contentsï¼‰çš„ä½ç½®ã€‚
        
        è«‹å‘Šè¨´æˆ‘ï¼š
        1. æ˜¯å¦æœ‰ç›®éŒ„é ï¼Ÿ
        2. å¦‚æœæœ‰ï¼Œç›®éŒ„é åœ¨ç¬¬å¹¾é ï¼Ÿï¼ˆå¾1é–‹å§‹è¨ˆç®—ï¼‰
        
        æ³¨æ„ï¼š
        - ç›®éŒ„é é€šå¸¸åŒ…å«ç« ç¯€æ¨™é¡Œå’Œå°æ‡‰çš„é æ•¸ã€‚
        - ç›®éŒ„é å¯èƒ½åŒ…å«å¤šé ï¼Œè«‹ä¸è¦è½ä¸‹ä»»ä½•ä¸€é ã€‚
        """

        pdf_part = {"inline_data": {"mime_type": "application/pdf", "data": base64_pdf}}

        print("æ­£åœ¨å°‹æ‰¾ç›®éŒ„é ä½ç½®...")

        response = client.models.generate_content(
            model="gemini-2.5-flash-preview-05-20",
            contents=[prompt, pdf_part],
            config={
                "response_mime_type": "application/json",
                "response_schema": TableOfContentsInfo,
            },
        )

        # è¨˜éŒ„tokenä½¿ç”¨é‡
        record_token_usage("å°‹æ‰¾ç›®éŒ„é ä½ç½®", response)

        result: TableOfContentsInfo = response.parsed
        return result

    except Exception as e:
        print(f"å°‹æ‰¾ç›®éŒ„é æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
        return None


def extract_specific_page_to_base64(pdf_path: str, page_numbers: List[int]) -> Optional[str]:
    """
    æå–PDFçš„ç‰¹å®šé é¢ä¸¦è½‰æ›ç‚ºbase64ç·¨ç¢¼

    Args:
        pdf_path (str): PDFæª”æ¡ˆè·¯å¾‘
        page_numbers (List[int]): è¦æå–çš„é æ•¸åˆ—è¡¨ï¼ˆå¾1é–‹å§‹ï¼‰

    Returns:
        Optional[str]: base64ç·¨ç¢¼çš„PDFé é¢ï¼Œå¦‚æœå¤±æ•—å‰‡è¿”å›None
    """
    try:
        with open(pdf_path, "rb") as file:
            pdf_reader = PyPDF2.PdfReader(file)

            total_pages = len(pdf_reader.pages)
            for page_number in page_numbers:
                if page_number < 1 or page_number > total_pages:
                    print(f"éŒ¯èª¤: é æ•¸ {page_number} è¶…å‡ºç¯„åœ (1-{total_pages})")
                    return None

            # å»ºç«‹æ–°çš„PDF writerï¼ŒåªåŒ…å«æŒ‡å®šé é¢
            pdf_writer = PyPDF2.PdfWriter()
            for page_number in page_numbers:
                page = pdf_reader.pages[page_number - 1]  # è½‰æ›ç‚º0-basedç´¢å¼•
                pdf_writer.add_page(page)

            # å°‡é é¢å¯«å…¥è¨˜æ†¶é«”
            output_buffer = io.BytesIO()
            pdf_writer.write(output_buffer)

            # å–å¾—PDFçš„äºŒé€²åˆ¶è³‡æ–™
            pdf_bytes = output_buffer.getvalue()

            # è½‰æ›ç‚ºbase64ç·¨ç¢¼
            base64_encoded = base64.b64encode(pdf_bytes).decode("utf-8")

            print(f"æˆåŠŸæå–ç¬¬ {page_numbers} é ä¸¦è½‰æ›ç‚ºbase64ç·¨ç¢¼")
            return base64_encoded

    except FileNotFoundError:
        print(f"éŒ¯èª¤: æ‰¾ä¸åˆ°æª”æ¡ˆ {pdf_path}")
        return None
    except Exception as e:
        print(f"æå–é é¢æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
        return None


def ask_gemini_about_toc_content(
    base64_toc_page: str,
) -> Optional[FinancialStatementsAnalysis]:
    """
    åˆ†æç›®éŒ„é å…§å®¹ï¼Œæ‰¾å‡ºè²¡å‹™å ±è¡¨é …ç›®çš„é æ•¸

    Args:
        base64_toc_page (str): base64ç·¨ç¢¼çš„ç›®éŒ„é å…§å®¹

    Returns:
        Optional[FinancialStatementsAnalysis]: çµæ§‹åŒ–çš„åˆ†æçµæœï¼Œå¦‚æœå¤±æ•—å‰‡è¿”å›None
    """
    try:
        client = setup_gemini()
        if not client:
            return None

        prompt = """
        è«‹åˆ†æé€™å€‹ç›®éŒ„é ï¼Œæ‰¾å‡ºä»¥ä¸‹è²¡å‹™å ±è¡¨é …ç›®åœ¨ç›®éŒ„ä¸­é¡¯ç¤ºçš„é æ•¸ï¼š

        1. å€‹é«”è³‡ç”¢è² å‚µè¡¨
        2. å€‹é«”ç¶œåˆæç›Šè¡¨  
        3. å€‹é«”æ¬Šç›Šè®Šå‹•è¡¨
        4. å€‹é«”ç¾é‡‘æµé‡è¡¨
        5. é‡è¦æœƒè¨ˆé …ç›®æ˜ç´°è¡¨

        è«‹ä»”ç´°æŸ¥çœ‹ç›®éŒ„ä¸­çš„é …ç›®åç¨±ï¼Œå¯èƒ½æœƒæœ‰é¡ä¼¼çš„è¡¨é”æ–¹å¼ï¼Œä¾‹å¦‚ï¼š
        - "è³‡ç”¢è² å‚µè¡¨"ã€"Balance Sheet"
        - "ç¶œåˆæç›Šè¡¨"ã€"Comprehensive Income Statement"
        - "æ¬Šç›Šè®Šå‹•è¡¨"ã€"Statement of Changes in Equity"
        - "ç¾é‡‘æµé‡è¡¨"ã€"Cash Flow Statement"
        - "é‡è¦æœƒè¨ˆé …ç›®æ˜ç´°è¡¨"ã€"Notes to Financial Statements"ã€"é™„è¨»"

        æ³¨æ„ï¼š
        - è«‹æ ¹æ“šç›®éŒ„ä¸­é¡¯ç¤ºçš„é æ•¸å¡«å¯«
        - å¦‚æœæ‰¾ä¸åˆ°æŸå€‹é …ç›®ï¼Œè«‹å°‡foundè¨­ç‚ºfalse
        - å¦‚æœæŸå€‹å ±è¡¨è·¨è¶Šå¤šé ï¼Œè«‹åˆ—å‡ºæ‰€æœ‰ç›¸é—œé æ•¸
        - é‡è¦æœƒè¨ˆé …ç›®æ˜ç´°è¡¨ä¸ç­‰æ–¼é‡è¦æœƒè¨ˆé …ç›®ä¹‹èªªæ˜ï¼Œè«‹æ³¨æ„å€åˆ†
        """

        toc_part = {
            "inline_data": {"mime_type": "application/pdf", "data": base64_toc_page}
        }

        print("æ­£åœ¨åˆ†æç›®éŒ„é å…§å®¹...")

        response = client.models.generate_content(
            model="gemini-2.5-flash-preview-05-20",
            contents=[prompt, toc_part],
            config={
                "response_mime_type": "application/json",
                "response_schema": FinancialStatementsAnalysis,
            },
        )

        # è¨˜éŒ„tokenä½¿ç”¨é‡
        record_token_usage("åˆ†æç›®éŒ„é å…§å®¹", response)

        result: FinancialStatementsAnalysis = response.parsed
        return result

    except Exception as e:
        print(f"åˆ†æç›®éŒ„é å…§å®¹æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
        return None


def extract_pages_range_to_base64(
    pdf_path: str, page_numbers: List[int]
) -> Optional[str]:
    """
    æå–PDFçš„å¤šå€‹é é¢ä¸¦è½‰æ›ç‚ºbase64ç·¨ç¢¼

    Args:
        pdf_path (str): PDFæª”æ¡ˆè·¯å¾‘
        page_numbers (List[int]): è¦æå–çš„é æ•¸åˆ—è¡¨ï¼ˆå¾1é–‹å§‹ï¼‰

    Returns:
        Optional[str]: base64ç·¨ç¢¼çš„PDFé é¢ï¼Œå¦‚æœå¤±æ•—å‰‡è¿”å›None
    """
    try:
        with open(pdf_path, "rb") as file:
            pdf_reader = PyPDF2.PdfReader(file)
            total_pages = len(pdf_reader.pages)

            # å»ºç«‹æ–°çš„PDF writer
            pdf_writer = PyPDF2.PdfWriter()

            for page_num in page_numbers:
                if page_num < 1 or page_num > total_pages:
                    print(f"è­¦å‘Š: é æ•¸ {page_num} è¶…å‡ºç¯„åœ (1-{total_pages})ï¼Œè·³é")
                    continue

                page = pdf_reader.pages[page_num - 1]  # è½‰æ›ç‚º0-basedç´¢å¼•
                pdf_writer.add_page(page)

            if len(pdf_writer.pages) == 0:
                print("éŒ¯èª¤: æ²’æœ‰æœ‰æ•ˆçš„é é¢å¯æå–")
                return None

            # å°‡é é¢å¯«å…¥è¨˜æ†¶é«”
            output_buffer = io.BytesIO()
            pdf_writer.write(output_buffer)

            # å–å¾—PDFçš„äºŒé€²åˆ¶è³‡æ–™
            pdf_bytes = output_buffer.getvalue()

            # è½‰æ›ç‚ºbase64ç·¨ç¢¼
            base64_encoded = base64.b64encode(pdf_bytes).decode("utf-8")

            print(f"æˆåŠŸæå–é æ•¸ {page_numbers} ä¸¦è½‰æ›ç‚ºbase64ç·¨ç¢¼")
            return base64_encoded

    except FileNotFoundError:
        print(f"éŒ¯èª¤: æ‰¾ä¸åˆ°æª”æ¡ˆ {pdf_path}")
        return None
    except Exception as e:
        print(f"æå–é é¢æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
        return None

def extract_pages_range_to_base64_with_mapping(
    pdf_path: str,
    page_numbers: List[int],
) -> Tuple[str, Dict[int, int], str]:
    """
    æŠ½å–å¤šé  PDF â†’ é‡æ–°ç·¨è™Ÿ â†’ å›å‚³
    1. base64 ç·¨ç¢¼å¾Œçš„åˆä½µ PDF
    2. æ–°èˆŠé ç¢¼å°ç…§ dict   (key = æ–°é †åº, value = åŸå§‹é ç¢¼)
    3. å¯ç›´æ¥å¡åˆ° Gemini prompt çš„ system_hint

    Args:
        pdf_path (str): PDF è·¯å¾‘
        page_numbers (List[int]): 1-based åŸå§‹é ç¢¼æ¸…å–®

    Returns:
        Tuple[str, Dict[int,int], str]:
            (pages_base64, page_mapping, system_hint)
        è‹¥å¤±æ•—å‰‡ raise Exception
    """
    # å…ˆæ’åºã€å»é‡
    unique_pages = sorted(set(page_numbers))
    if not unique_pages:
        raise ValueError("page_numbers ä¸èƒ½ç‚ºç©º")

    reader = PyPDF2.PdfReader(pdf_path)
    total_pages = len(reader.pages)

    writer = PyPDF2.PdfWriter()
    page_mapping: Dict[int, int] = {}

    for new_idx, orig_page in enumerate(unique_pages, start=1):
        if orig_page < 1 or orig_page > total_pages:
            raise ValueError(f"é ç¢¼ {orig_page} è¶…å‡ºç¯„åœ 1-{total_pages}")
        writer.add_page(reader.pages[orig_page - 1])
        page_mapping[new_idx] = orig_page     # å»ºç«‹å°ç…§è¡¨

    # åˆä½µå¾Œè½‰ base64
    out_buf = io.BytesIO()
    writer.write(out_buf)
    pdf_bytes = out_buf.getvalue()
    pages_base64 = base64.b64encode(pdf_bytes).decode()

    # ç”¢ç”Ÿ system hint
    mapping_lines = [
        f"æ–°ç·¨è™Ÿç¬¬ {new} é  = åŸå§‹é ç¢¼ç¬¬ {orig} é "
        for new, orig in page_mapping.items()
    ]
    system_hint = (
        "âš ï¸ **é ç¢¼å°ç…§æé†’**ï¼šä»¥ä¸‹ PDF ç‚ºç¯€çœ token åªæŠ½å–éƒ¨åˆ†é é¢ã€‚\n"
        "è«‹å‹™å¿…ä½¿ç”¨ã€ŒåŸå§‹é ç¢¼ã€å›ç­”ã€‚\n\n"
        + "\n".join(mapping_lines)
    )

    return pages_base64, page_mapping, system_hint
def process_financial_models(
    pdf_path: str, financial_analysis: FinancialStatementsAnalysis
):
    """
    è™•ç†4å€‹è²¡å‹™æ¨¡å‹ï¼Œæ ¹æ“šåˆ†æçµæœæå–ç›¸é—œé æ•¸ä¸¦è©¢å•Gemini

    Args:
        pdf_path (str): PDFæª”æ¡ˆè·¯å¾‘
        financial_analysis (FinancialStatementsAnalysis): è²¡å‹™å ±è¡¨åˆ†æçµæœ
    """

    # å®šç¾©æ¨¡å‹é…ç½® - æ¯å€‹æ¨¡å‹æŒ‡å®šæ‰€éœ€çš„è²¡å‹™å ±è¡¨
    models_config = [
        {
            "name": "ç¾é‡‘åŠç´„ç•¶ç¾é‡‘",
            "model_class": CashAndEquivalents,
            "prompt": cash_equivalents_prompt,
            "required_statements": [
                "individual_balance_sheet",
                "important_accounting_items",
            ],
        },
        {
            "name": "é ä»˜æ¬¾é …",
            "model_class": PrePayments,
            "prompt": prepayments_prompt,
            "required_statements": [
                "individual_balance_sheet",
                "important_accounting_items",
            ],
        },
        {
            "name": "æ‡‰æ”¶é—œä¿‚äººæ¬¾é …",
            "model_class": ReceivablesRelatedParties,
            "prompt": receivables_related_parties_prompt,
            "required_statements": [
                "individual_balance_sheet",
                "important_accounting_items",
            ],
        },
        {
            "name": "è² å‚µç¸½é¡",
            "model_class": TotalLiabilities,
            "prompt": total_liabilities_prompt,
            "required_statements": [
                "individual_balance_sheet",
                "important_accounting_items",
            ],
        },
    ]

    # æ”¶é›†æ‰€æœ‰éœ€è¦çš„é æ•¸ï¼ˆæ ¹æ“šæ‰€æœ‰æ¨¡å‹çš„éœ€æ±‚ï¼‰
    all_required_statements = set()
    for model_config in models_config:
        all_required_statements.update(model_config["required_statements"])

    all_relevant_pages = set()
    for statement_name in all_required_statements:
        statement = getattr(financial_analysis, statement_name)
        if statement.found and statement.page_numbers:
            all_relevant_pages.update(statement.page_numbers)
            print(f"ğŸ“‹ {statement_name}: é æ•¸ {statement.page_numbers}")

    if not all_relevant_pages:
        print("éŒ¯èª¤: æ²’æœ‰æ‰¾åˆ°ç›¸é—œçš„è²¡å‹™å ±è¡¨é æ•¸")
        return

    relevant_pages = sorted(list(all_relevant_pages))
    print(f"ğŸ“„ ç¸½å…±éœ€è¦æå–çš„é æ•¸: {relevant_pages}")

    # æå–ç›¸é—œé é¢
    pages_base64, page_mapping, system_hint = (
    extract_pages_range_to_base64_with_mapping(pdf_path, relevant_pages)
    )

    pdf_part = {
        "inline_data": {"mime_type": "application/pdf", "data": pages_base64}
    }

    if not pages_base64:
        print("éŒ¯èª¤: ç„¡æ³•æå–ç›¸é—œé é¢")
        return

    # è™•ç†æ¯å€‹æ¨¡å‹
    results = {}

    for model_config in models_config:
        print(f"\n=== è™•ç† {model_config['name']} æ¨¡å‹ ===")

        # é¡¯ç¤ºæ­¤æ¨¡å‹éœ€è¦çš„å ±è¡¨
        print(f"ğŸ“‹ éœ€è¦çš„å ±è¡¨: {', '.join(model_config['required_statements'])}")

        # æª¢æŸ¥æ‰€éœ€å ±è¡¨æ˜¯å¦éƒ½æ‰¾åˆ°äº†
        missing_statements = []
        for req_statement in model_config["required_statements"]:
            statement = getattr(financial_analysis, req_statement)
            if not statement.found:
                missing_statements.append(req_statement)

        if missing_statements:
            print(f"âš ï¸  è­¦å‘Š: ä»¥ä¸‹å¿…éœ€å ±è¡¨æœªæ‰¾åˆ°: {', '.join(missing_statements)}")
            print(f"ğŸ”„ ä»å°‡å˜—è©¦è™•ç† {model_config['name']}...")

        try:
            client = setup_gemini()
            if not client:
                print(f"ç„¡æ³•è¨­å®šGeminiå®¢æˆ¶ç«¯ï¼Œè·³é {model_config['name']}")
                continue

            # æº–å‚™PDFè³‡æ–™
            pdf_part = {
                "inline_data": {"mime_type": "application/pdf", "data": pages_base64}
            }

            print(f"æ­£åœ¨å‘Geminiç™¼é€ {model_config['name']} åˆ†æè«‹æ±‚...")

            # ç™¼é€è«‹æ±‚çµ¦Gemini
            response = client.models.generate_content(
                model="gemini-2.5-flash-preview-05-20",
                contents=[system_hint, model_config["prompt"], pdf_part],
                config={
                    "response_mime_type": "application/json",
                    "response_schema": model_config["model_class"],
                },
            )

            # è¨˜éŒ„tokenä½¿ç”¨é‡
            record_token_usage(f"è™•ç†{model_config['name']}æ¨¡å‹", response)

            # ç²å–çµæ§‹åŒ–çµæœ
            result = response.parsed
            results[model_config["name"]] = result

            # å„²å­˜åˆ°å…¨åŸŸçµ±è¨ˆä¸­
            processing_stats.model_results[model_config["name"]] = result

            print(f"âœ… {model_config['name']} åˆ†æå®Œæˆ")

        except Exception as e:
            print(f"âŒ è™•ç† {model_config['name']} æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
            results[model_config["name"]] = None
            processing_stats.model_results[model_config["name"]] = None

    # é¡¯ç¤ºçµæœæ‘˜è¦
    print(f"\n=== è™•ç†çµæœæ‘˜è¦ ===")
    for model_name, result in results.items():
        if result:
            print(f"âœ… {model_name}: æˆåŠŸ")
        else:
            print(f"âŒ {model_name}: å¤±æ•—")

    return results


class ValidationResult(BaseModel):
    """é©—è­‰çµæœ"""

    model_name: str = Field(description="æ¨¡å‹åç¨±")
    is_valid: bool = Field(description="æ•¸å­—æ˜¯å¦æ­£ç¢º")
    errors: List[str] = Field(default_factory=list, description="ç™¼ç¾çš„éŒ¯èª¤åˆ—è¡¨")
    warnings: List[str] = Field(default_factory=list, description="è­¦å‘Šåˆ—è¡¨")
    confidence_score: float = Field(description="ä¿¡å¿ƒåˆ†æ•¸ (0-1)")
    notes: Optional[str] = Field(default=None, description="é¡å¤–å‚™è¨»")


class OverallValidationResult(BaseModel):
    """æ•´é«”é©—è­‰çµæœ"""

    validation_results: List[ValidationResult] = Field(description="å„æ¨¡å‹é©—è­‰çµæœ")
    overall_valid: bool = Field(description="æ•´é«”æ˜¯å¦é€šéé©—è­‰")
    total_errors: int = Field(description="ç¸½éŒ¯èª¤æ•¸")
    total_warnings: int = Field(description="ç¸½è­¦å‘Šæ•¸")
    average_confidence: float = Field(description="å¹³å‡ä¿¡å¿ƒåˆ†æ•¸")


def validate_extracted_data(
    pdf_path: str,
    financial_analysis: FinancialStatementsAnalysis,
    model_results: Dict[str, Any],
) -> Optional[OverallValidationResult]:
    """
    é©—è­‰æå–çš„æ•¸æ“šæ˜¯å¦æ­£ç¢º

    Args:
        pdf_path (str): PDFæª”æ¡ˆè·¯å¾‘
        financial_analysis (FinancialStatementsAnalysis): è²¡å‹™å ±è¡¨åˆ†æçµæœ
        model_results (Dict[str, Any]): æ¨¡å‹æå–çµæœ

    Returns:
        Optional[OverallValidationResult]: é©—è­‰çµæœ
    """
    print("\n=== é–‹å§‹æ•¸æ“šé©—è­‰æª¢æŸ¥ ===")

    # æ”¶é›†æ‰€æœ‰ç›¸é—œé æ•¸ï¼ˆåŒ…å«æ‰€æœ‰æ‰¾åˆ°çš„è²¡å‹™å ±è¡¨ï¼‰
    all_relevant_pages = set()
    for attr_name in [
        "individual_balance_sheet",
        "individual_comprehensive_income",
        "individual_equity_changes",
        "individual_cash_flow",
        "important_accounting_items",
    ]:
        statement = getattr(financial_analysis, attr_name)
        if statement.found and statement.page_numbers:
            all_relevant_pages.update(statement.page_numbers)
            print(f"ğŸ“„ é©—è­‰å°‡ä½¿ç”¨ {attr_name}: é æ•¸ {statement.page_numbers}")

    if not all_relevant_pages:
        print("éŒ¯èª¤: æ²’æœ‰æ‰¾åˆ°ç›¸é—œçš„è²¡å‹™å ±è¡¨é æ•¸é€²è¡Œé©—è­‰")
        return None

    relevant_pages = sorted(list(all_relevant_pages))
    print(f"ğŸ“„ é©—è­‰ç¸½å…±ä½¿ç”¨é æ•¸: {relevant_pages}")
    pages_base64 = extract_pages_range_to_base64(pdf_path, relevant_pages)

    if not pages_base64:
        print("éŒ¯èª¤: ç„¡æ³•æå–ç›¸é—œé é¢é€²è¡Œé©—è­‰")
        return None

    validation_results = []

    for model_name, result in model_results.items():
        if result is None:
            print(f"è·³é {model_name} é©—è­‰ï¼ˆç„¡çµæœï¼‰")
            continue

        print(f"\nğŸ” é©—è­‰ {model_name} æ•¸æ“š...")

        try:
            client = setup_gemini()
            if not client:
                print(f"ç„¡æ³•è¨­å®šGeminiå®¢æˆ¶ç«¯ï¼Œè·³é {model_name} é©—è­‰")
                continue

            # å°‡çµæœè½‰æ›ç‚ºJSONå­—ä¸²
            if hasattr(result, "model_dump"):
                result_json = json.dumps(
                    result.model_dump(), ensure_ascii=False, indent=2
                )
            elif hasattr(result, "dict"):
                result_json = json.dumps(result.dict(), ensure_ascii=False, indent=2)
            else:
                result_json = json.dumps(result, ensure_ascii=False, indent=2)

            # æº–å‚™é©—è­‰æç¤ºè©
            validation_prompt = f"""
è«‹ä½ ä½œç‚ºä¸€å€‹åš´æ ¼çš„è²¡å‹™æ•¸æ“šå¯©æ ¸å“¡ï¼Œä»”ç´°æª¢æŸ¥ä»¥ä¸‹æå–çš„ {model_name} æ•¸æ“šæ˜¯å¦æ­£ç¢ºã€‚

æå–çš„æ•¸æ“šï¼š
{result_json}

è«‹åŸ·è¡Œä»¥ä¸‹æª¢æŸ¥ï¼š

1. **æ•¸å­—æº–ç¢ºæ€§æª¢æŸ¥**ï¼š
   - ä»”ç´°å°æ¯”PDFä¸­çš„åŸå§‹æ•¸å­—èˆ‡æå–çš„æ•¸å­—
   - æª¢æŸ¥æ˜¯å¦æœ‰æ•¸å­—éŒ¯èª¤ã€éºæ¼æˆ–å¤šé¤˜çš„æ•¸å­—
   - æ³¨æ„å°æ•¸é»ä½ç½®ã€åƒåˆ†ä½ç¬¦è™Ÿ
   - æª¢æŸ¥è² æ•¸æ˜¯å¦æ­£ç¢ºè­˜åˆ¥ï¼ˆæ‹¬è™Ÿè¡¨ç¤ºè² æ•¸ï¼‰

2. **å–®ä½ä¸€è‡´æ€§æª¢æŸ¥**ï¼š
   - æª¢æŸ¥ unit_is_thousand æ¬„ä½æ˜¯å¦æ­£ç¢º
   - ç¢ºèªæ•¸å€¼å–®ä½èˆ‡PDFä¸­çš„å–®ä½èªªæ˜ä¸€è‡´
   - æ³¨æ„æ˜¯å¦æœ‰æ··åˆå–®ä½çš„æƒ…æ³

3. **é æ•¸å’Œæ¨™ç±¤æª¢æŸ¥**ï¼š
   - é©—è­‰ source_page æ˜¯å¦æŒ‡å‘æ­£ç¢ºçš„é é¢
   - æª¢æŸ¥ source_label æ˜¯å¦æº–ç¢ºåæ˜ åŸæ–‡è¡¨å

4. **é‚è¼¯ä¸€è‡´æ€§æª¢æŸ¥**ï¼š
   - æª¢æŸ¥ç›¸é—œæ•¸å­—ä¹‹é–“çš„é‚è¼¯é—œä¿‚
   - é©—è­‰åˆè¨ˆæ•¸æ˜¯å¦æ­£ç¢º
   - æª¢æŸ¥æ˜¯å¦æœ‰æ˜é¡¯ä¸åˆç†çš„æ•¸å€¼

5. **å®Œæ•´æ€§æª¢æŸ¥**ï¼š
   - ç¢ºèªæ‰€æœ‰æ‡‰è©²å¡«å…¥çš„æ¬„ä½éƒ½æœ‰æ•¸æ“š
   - æª¢æŸ¥æ˜¯å¦æœ‰éºæ¼çš„é‡è¦é …ç›®

è«‹æä¾›ï¼š
- is_valid: æ•¸æ“šæ˜¯å¦å®Œå…¨æ­£ç¢ºï¼ˆå¸ƒæ—å€¼ï¼‰
- errors: ç™¼ç¾çš„å…·é«”éŒ¯èª¤ï¼ˆå¦‚æœæœ‰ï¼‰
- warnings: éœ€è¦æ³¨æ„çš„å•é¡Œï¼ˆå¦‚æœæœ‰ï¼‰
- confidence_score: å°é©—è­‰çµæœçš„ä¿¡å¿ƒåˆ†æ•¸ï¼ˆ0-1ï¼Œ1è¡¨ç¤ºéå¸¸ç¢ºä¿¡ï¼‰
- notes: é¡å¤–çš„é©—è­‰èªªæ˜

è¦æ±‚ï¼š
- è«‹æ¥µå…¶åš´æ ¼åœ°æª¢æŸ¥æ¯ä¸€å€‹æ•¸å­—
- å³ä½¿æ˜¯å¾®å°çš„å·®ç•°ä¹Ÿè¦æŒ‡å‡º
- å¦‚æœç„¡æ³•ç¢ºå®šæŸå€‹æ•¸å­—æ˜¯å¦æ­£ç¢ºï¼Œè«‹åœ¨warningsä¸­èªªæ˜
- åªæœ‰åœ¨100%ç¢ºä¿¡æ‰€æœ‰æ•¸å­—éƒ½æ­£ç¢ºæ™‚ï¼Œæ‰å°‡is_validè¨­ç‚ºtrue
"""

            # æº–å‚™PDFè³‡æ–™
            pdf_part = {
                "inline_data": {"mime_type": "application/pdf", "data": pages_base64}
            }

            # ç™¼é€é©—è­‰è«‹æ±‚
            response = client.models.generate_content(
                model="gemini-2.5-flash-preview-05-20",
                contents=[validation_prompt, pdf_part],
                config={
                    "response_mime_type": "application/json",
                    "response_schema": ValidationResult,
                },
            )

            # è¨˜éŒ„tokenä½¿ç”¨é‡
            record_token_usage(f"é©—è­‰{model_name}æ•¸æ“š", response)

            # ç²å–é©—è­‰çµæœ
            validation_result = response.parsed
            validation_result.model_name = model_name
            validation_results.append(validation_result)

            # é¡¯ç¤ºé©—è­‰çµæœ
            if validation_result.is_valid:
                print(
                    f"âœ… {model_name} é©—è­‰é€šé (ä¿¡å¿ƒåˆ†æ•¸: {validation_result.confidence_score:.2f})"
                )
            else:
                print(
                    f"âŒ {model_name} é©—è­‰å¤±æ•— (ä¿¡å¿ƒåˆ†æ•¸: {validation_result.confidence_score:.2f})"
                )
                if validation_result.errors:
                    print(f"   éŒ¯èª¤: {', '.join(validation_result.errors)}")

            if validation_result.warnings:
                print(f"âš ï¸  è­¦å‘Š: {', '.join(validation_result.warnings)}")

            if validation_result.notes:
                print(f"ğŸ“ å‚™è¨»: {validation_result.notes}")

        except Exception as e:
            print(f"âŒ é©—è­‰ {model_name} æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
            # å‰µå»ºå¤±æ•—çš„é©—è­‰çµæœ
            validation_results.append(
                ValidationResult(
                    model_name=model_name,
                    is_valid=False,
                    errors=[f"é©—è­‰éç¨‹ç™¼ç”ŸéŒ¯èª¤: {str(e)}"],
                    warnings=[],
                    confidence_score=0.0,
                    notes="é©—è­‰éç¨‹ä¸­ç™¼ç”ŸæŠ€è¡“éŒ¯èª¤",
                )
            )

    # è¨ˆç®—æ•´é«”é©—è­‰çµæœ
    if validation_results:
        total_errors = sum(len(vr.errors) for vr in validation_results)
        total_warnings = sum(len(vr.warnings) for vr in validation_results)
        average_confidence = sum(
            vr.confidence_score for vr in validation_results
        ) / len(validation_results)
        overall_valid = all(vr.is_valid for vr in validation_results)

        overall_result = OverallValidationResult(
            validation_results=validation_results,
            overall_valid=overall_valid,
            total_errors=total_errors,
            total_warnings=total_warnings,
            average_confidence=average_confidence,
        )

        print(f"\nğŸ“Š æ•´é«”é©—è­‰çµæœ:")
        print(f"   é€šéé©—è­‰: {'æ˜¯' if overall_valid else 'å¦'}")
        print(f"   ç¸½éŒ¯èª¤æ•¸: {total_errors}")
        print(f"   ç¸½è­¦å‘Šæ•¸: {total_warnings}")
        print(f"   å¹³å‡ä¿¡å¿ƒåˆ†æ•¸: {average_confidence:.2f}")

        return overall_result

    return None


def display_validation_summary(validation_result: OverallValidationResult):
    """é¡¯ç¤ºè©³ç´°çš„é©—è­‰æ‘˜è¦"""
    print("\n" + "=" * 80)
    print("ğŸ” æ•¸æ“šé©—è­‰è©³ç´°å ±å‘Š")
    print("=" * 80)

    for vr in validation_result.validation_results:
        print(f"\nğŸ“‹ {vr.model_name}:")
        print(f"   ç‹€æ…‹: {'âœ… é€šé' if vr.is_valid else 'âŒ å¤±æ•—'}")
        print(f"   ä¿¡å¿ƒåˆ†æ•¸: {vr.confidence_score:.2f}")

        if vr.errors:
            print(f"   éŒ¯èª¤:")
            for error in vr.errors:
                print(f"     â€¢ {error}")

        if vr.warnings:
            print(f"   è­¦å‘Š:")
            for warning in vr.warnings:
                print(f"     â€¢ {warning}")

        if vr.notes:
            print(f"   å‚™è¨»: {vr.notes}")

    print(f"\nğŸ“Š ç¸½çµ:")
    print(f"   æ•´é«”é©—è­‰: {'âœ… é€šé' if validation_result.overall_valid else 'âŒ å¤±æ•—'}")
    print(f"   ç¸½éŒ¯èª¤æ•¸: {validation_result.total_errors}")
    print(f"   ç¸½è­¦å‘Šæ•¸: {validation_result.total_warnings}")
    print(f"   å¹³å‡ä¿¡å¿ƒåˆ†æ•¸: {validation_result.average_confidence:.2f}")

    if validation_result.overall_valid:
        print("\nğŸ‰ æ‰€æœ‰æ•¸æ“šéƒ½é€šéäº†åš´æ ¼é©—è­‰ï¼")
    else:
        print("\nâš ï¸  ç™¼ç¾æ•¸æ“šå•é¡Œï¼Œå»ºè­°æª¢æŸ¥ä¸¦ä¿®æ­£ã€‚")

    print("=" * 80)


# ä½¿ç”¨ç¯„ä¾‹
if __name__ == "__main__":
    # é‡ç½®çµ±è¨ˆ
    processing_stats.token_usage.clear()
    processing_stats.model_results.clear()
    processing_stats.total_tokens = 0

    print("ğŸš€ é–‹å§‹è™•ç†è²¡å‹™å ±è¡¨...")

    # è«‹å°‡ 'your_pdf_file.pdf' æ›¿æ›ç‚ºå¯¦éš›çš„PDFæª”æ¡ˆè·¯å¾‘
    pdf_file_path = "assets/pdfs/quartely-results-2024-zh_tcm27-94407.pdf"
    print(f"æ­£åœ¨è™•ç†çš„PDFæª”æ¡ˆè·¯å¾‘: {pdf_file_path}")
    # æ­¥é©Ÿ1: æå–PDFå‰5é ä¸¦è½‰æ›ç‚ºbase64
    result = extract_first_ten_pages_to_base64(pdf_file_path)

    if result:
        print("PDFå‰5é å·²æˆåŠŸè½‰æ›ç‚ºbase64ç·¨ç¢¼")

        # æ­¥é©Ÿ2: å°‹æ‰¾ç›®éŒ„é ä½ç½®
        print("\n=== å°‹æ‰¾ç›®éŒ„é ä½ç½® ===")
        toc_info = find_table_of_contents_page(result)

        if toc_info and toc_info.has_toc and toc_info.toc_page_numbers:
            print(f"Geminiå»ºè­°ç›®éŒ„é åœ¨ç¬¬ {toc_info.toc_page_numbers} é ")
            if toc_info.notes:
                print(f"å‚™è¨»: {toc_info.notes}")

            # æ­¥é©Ÿ3: æå–ç›®éŒ„é 
            print(f"\n=== æå–ç¬¬ {toc_info.toc_page_numbers} é ç›®éŒ„å…§å®¹ ===")
            toc_page_base64 = extract_specific_page_to_base64(
                pdf_file_path, toc_info.toc_page_numbers
            )

            if toc_page_base64:
                # æ­¥é©Ÿ4: åˆ†æç›®éŒ„é å…§å®¹ï¼Œæ‰¾å‡ºè²¡å‹™å ±è¡¨é …ç›®çš„é æ•¸
                print("\n=== åˆ†æç›®éŒ„é ä¸­çš„è²¡å‹™å ±è¡¨é …ç›®ä½ç½® ===")
                financial_analysis = ask_gemini_about_toc_content(toc_page_base64)

                if financial_analysis:
                    print("æ ¹æ“šç›®éŒ„é åˆ†æçš„è²¡å‹™å ±è¡¨é …ç›®ä½ç½®:")
                    print(f"\n1. å€‹é«”è³‡ç”¢è² å‚µè¡¨:")
                    print(
                        f"   - æ‰¾åˆ°: {'æ˜¯' if financial_analysis.individual_balance_sheet.found else 'å¦'}"
                    )
                    print(
                        f"   - é æ•¸: {financial_analysis.individual_balance_sheet.page_numbers}"
                    )
                    if financial_analysis.individual_balance_sheet.notes:
                        print(
                            f"   - å‚™è¨»: {financial_analysis.individual_balance_sheet.notes}"
                        )

                    print(f"\n2. å€‹é«”ç¶œåˆæç›Šè¡¨:")
                    print(
                        f"   - æ‰¾åˆ°: {'æ˜¯' if financial_analysis.individual_comprehensive_income.found else 'å¦'}"
                    )
                    print(
                        f"   - é æ•¸: {financial_analysis.individual_comprehensive_income.page_numbers}"
                    )
                    if financial_analysis.individual_comprehensive_income.notes:
                        print(
                            f"   - å‚™è¨»: {financial_analysis.individual_comprehensive_income.notes}"
                        )

                    print(f"\n3. å€‹é«”æ¬Šç›Šè®Šå‹•è¡¨:")
                    print(
                        f"   - æ‰¾åˆ°: {'æ˜¯' if financial_analysis.individual_equity_changes.found else 'å¦'}"
                    )
                    print(
                        f"   - é æ•¸: {financial_analysis.individual_equity_changes.page_numbers}"
                    )
                    if financial_analysis.individual_equity_changes.notes:
                        print(
                            f"   - å‚™è¨»: {financial_analysis.individual_equity_changes.notes}"
                        )

                    print(f"\n4. å€‹é«”ç¾é‡‘æµé‡è¡¨:")
                    print(
                        f"   - æ‰¾åˆ°: {'æ˜¯' if financial_analysis.individual_cash_flow.found else 'å¦'}"
                    )
                    print(
                        f"   - é æ•¸: {financial_analysis.individual_cash_flow.page_numbers}"
                    )
                    if financial_analysis.individual_cash_flow.notes:
                        print(
                            f"   - å‚™è¨»: {financial_analysis.individual_cash_flow.notes}"
                        )

                    print(f"\n5. é‡è¦æœƒè¨ˆé …ç›®æ˜ç´°è¡¨:")
                    print(
                        f"   - æ‰¾åˆ°: {'æ˜¯' if financial_analysis.important_accounting_items.found else 'å¦'}"
                    )
                    print(
                        f"   - é æ•¸: {financial_analysis.important_accounting_items.page_numbers}"
                    )
                    if financial_analysis.important_accounting_items.notes:
                        print(
                            f"   - å‚™è¨»: {financial_analysis.important_accounting_items.notes}"
                        )

                    # æ­¥é©Ÿ5: è™•ç†4å€‹è²¡å‹™æ¨¡å‹
                    print(f"\n=== è™•ç†è²¡å‹™æ¨¡å‹ ===")
                    model_results = process_financial_models(
                        pdf_file_path, financial_analysis
                    )

                    if model_results:
                        print(f"\n=== è²¡å‹™æ¨¡å‹è™•ç†å®Œæˆ ===")
                        for model_name, result in model_results.items():
                            if result:
                                print(f"âœ… {model_name}: è³‡æ–™å·²æˆåŠŸæå–ä¸¦çµæ§‹åŒ–")
                                display_model_result(model_name, result)
                            else:
                                print(f"âŒ {model_name}: è™•ç†å¤±æ•—")

                        # æ­¥é©Ÿ6: é©—è­‰æå–çš„æ•¸æ“š
                        print(f"\n=== æ•¸æ“šé©—è­‰æª¢æŸ¥ ===")
                        validation_result = validate_extracted_data(
                            pdf_file_path, financial_analysis, model_results
                        )
                        if validation_result:
                            display_validation_summary(validation_result)
                        else:
                            print("æ•¸æ“šé©—è­‰å¤±æ•—")
                    else:
                        print("è²¡å‹™æ¨¡å‹è™•ç†å¤±æ•—")
                else:
                    print("ç›®éŒ„é å…§å®¹åˆ†æå¤±æ•—")
            else:
                print("æå–ç›®éŒ„é å¤±æ•—")
        else:
            print("æœªæ‰¾åˆ°ç›®éŒ„é æˆ–ç›®éŒ„é è³‡è¨Šä¸å®Œæ•´")
            if toc_info and toc_info.notes:
                print(f"å‚™è¨»: {toc_info.notes}")
    else:
        print("è½‰æ›å¤±æ•—")

    # é¡¯ç¤ºæœ€çµ‚çµ±è¨ˆæ‘˜è¦
    display_final_summary()
