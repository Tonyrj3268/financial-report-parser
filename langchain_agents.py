 """
åŸºæ–¼ LangChain çš„æ™ºèƒ½è²¡å‹™å ±è¡¨è§£æ Agent ç³»çµ±

é€™å€‹ç³»çµ±ä½¿ç”¨ LangChain æ¡†æ¶æ§‹å»ºäº†ä¸€å€‹å¤š Agent å”ä½œçš„è²¡å‹™å ±è¡¨è§£æç³»çµ±ï¼Œ
èƒ½å¤ æ™ºèƒ½åœ°è™•ç† PDF è²¡å‹™å ±è¡¨ï¼Œè‡ªå‹•ç™¼ç¾å¼•ç”¨ï¼Œä¸¦æå–çµæ§‹åŒ–çš„è²¡å‹™æ•¸æ“šã€‚
"""

import PyPDF2
import base64
import io
import json
import os
from typing import Optional, List, Dict, Any, Type, Union
from dotenv import load_dotenv
from google.genai import Client

# LangChain imports
from langchain.tools import BaseTool
from langchain.agents import AgentExecutor, create_openai_functions_agent
from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_openai import ChatOpenAI
from langchain.callbacks.base import BaseCallbackHandler

# Pydantic imports
from pydantic import BaseModel, Field

# å°å…¥åŸæœ‰çš„æ¨¡å‹å®šç¾©
from src.models.cash_equivalents import CashAndEquivalents, cash_equivalents_prompt
from src.models.prepayments import PrePayments, prepayments_prompt
from src.models.receivables_related_parties import (
    ReceivablesRelatedParties,
    receivables_related_parties_prompt,
)
from src.models.total_liabilities import TotalLiabilities, total_liabilities_prompt

load_dotenv()


# ===============================
# æ•¸æ“šæ¨¡å‹å®šç¾©
# ===============================


class PDFProcessingState(BaseModel):
    """PDF è™•ç†ç‹€æ…‹è¿½è¹¤"""

    pdf_path: str
    current_step: str = "åˆå§‹åŒ–"
    pages_extracted: List[int] = Field(default_factory=list)
    toc_pages: Optional[List[int]] = None
    financial_statement_pages: Dict[str, List[int]] = Field(default_factory=dict)
    toc_analysis_result: Optional[Dict[str, Any]] = None  # æ–°å¢ï¼šå­˜å„²ç›®éŒ„åˆ†æçµæœ
    discovered_references: List[Dict[str, Any]] = Field(
        default_factory=list
    )  # æ–°å¢ï¼šå­˜å„²ç™¼ç¾çš„å¼•ç”¨
    additional_referenced_pages: List[int] = Field(default_factory=list)
    all_pages_base64: Optional[str] = None
    page_mapping: Dict[int, int] = Field(default_factory=dict)
    extraction_results: Dict[str, Any] = Field(default_factory=dict)
    incomplete_extractions: Dict[str, Any] = Field(
        default_factory=dict
    )  # æ–°å¢ï¼šå­˜å„²éœ€è¦è£œå……çš„æå–çµæœ
    errors: List[str] = Field(default_factory=list)

    class Config:
        arbitrary_types_allowed = True


class TableOfContentsInfo(BaseModel):
    """ç›®éŒ„é è³‡è¨Š"""

    has_toc: bool = Field(description="æ˜¯å¦æœ‰ç›®éŒ„é ")
    toc_page_numbers: Optional[List[int]] = Field(description="ç›®éŒ„é çš„é æ•¸åˆ—è¡¨")
    notes: Optional[str] = Field(default=None, description="é¡å¤–å‚™è¨»")


class ReferenceLocationResult(BaseModel):
    """å¼•ç”¨ä½ç½®çµæœ"""

    found: bool = Field(description="æ˜¯å¦æ‰¾åˆ°å¼•ç”¨")
    section_name: str = Field(description="ç« ç¯€åç¨±")
    page_numbers: List[int] = Field(description="è©²ç« ç¯€æ‰€åœ¨çš„é æ•¸åˆ—è¡¨")
    confidence_score: float = Field(description="æŸ¥æ‰¾çš„ä¿¡å¿ƒåˆ†æ•¸ï¼ˆ0-1ï¼‰")


class DiscoveredReferenceItem(BaseModel):
    """ç™¼ç¾çš„å¼•ç”¨é …ç›®"""

    reference_text: str = Field(description="å¼•ç”¨æ–‡æœ¬")
    context: str = Field(description="å¼•ç”¨ä¸Šä¸‹æ–‡")
    reference_type: Optional[str] = Field(
        default=None, description="å¼•ç”¨é¡å‹ï¼šé™„è¨»ã€æ˜ç´°è¡¨ã€èªªæ˜ç­‰"
    )
    page_numbers: Optional[List[int]] = Field(
        default=None, description="å¼•ç”¨æ‰€åœ¨çš„é æ•¸åˆ—è¡¨"
    )


class ExtractionResultWithReferences(BaseModel):
    """åŒ…å«å¼•ç”¨ä¿¡æ¯çš„æå–çµæœ"""

    extracted_data: Optional[
        Union[
            CashAndEquivalents, PrePayments, ReceivablesRelatedParties, TotalLiabilities
        ]
    ] = None
    discovered_references: Optional[List[DiscoveredReferenceItem]] = Field(
        default=None, description="ç™¼ç¾çš„å¼•ç”¨åˆ—è¡¨"
    )
    is_complete: bool = Field(description="æ•¸æ“šæ˜¯å¦å®Œæ•´")
    missing_info_description: Optional[str] = Field(
        default=None, description="å¦‚æœä¸å®Œæ•´ï¼Œæè¿°ç¼ºå¤±çš„ä¿¡æ¯"
    )


class FinancialStatementLocation(BaseModel):
    """è²¡å‹™å ±è¡¨é …ç›®ä½ç½®è³‡è¨Š"""

    item_name: str = Field(description="è²¡å‹™å ±è¡¨é …ç›®åç¨±")
    page_numbers: List[int] = Field(description="è©²é …ç›®æ‰€åœ¨çš„é æ•¸åˆ—è¡¨")
    found: bool = Field(description="æ˜¯å¦æ‰¾åˆ°è©²é …ç›®")
    notes: Optional[str] = Field(default=None, description="é¡å¤–å‚™è¨»")


class DetailSectionLocation(BaseModel):
    """å¾ç›®éŒ„ä¸­è§£æå‡ºçš„è©³ç´°ç« ç¯€ä½ç½®è³‡è¨Šï¼ˆä¾‹å¦‚é™„è¨»ä¸€ã€æŸæŸæ˜ç´°è¡¨ï¼‰"""

    section_name: str = Field(
        description="ç« ç¯€åç¨±ï¼Œä¾‹å¦‚ 'é™„è¨»ä¸€'ã€'ç¾é‡‘åŠç´„ç•¶ç¾é‡‘æ˜ç´°è¡¨'"
    )
    page_numbers: List[int] = Field(description="è©²ç« ç¯€æ‰€åœ¨çš„é æ•¸åˆ—è¡¨")
    found: bool = Field(description="æ˜¯å¦æ‰¾åˆ°è©²ç« ç¯€")
    notes: Optional[str] = Field(default=None, description="é¡å¤–å‚™è¨»")


class FinancialStatementsAnalysis(BaseModel):
    """è²¡å‹™å ±è¡¨åˆ†æçµæœ"""

    individual_balance_sheet: FinancialStatementLocation = Field(
        description="å€‹é«”è³‡ç”¢è² å‚µè¡¨"
    )
    individual_comprehensive_income: FinancialStatementLocation = Field(
        description="å€‹é«”ç¶œåˆæç›Šè¡¨"
    )
    individual_equity_changes: FinancialStatementLocation = Field(
        description="å€‹é«”æ¬Šç›Šè®Šå‹•è¡¨"
    )
    individual_cash_flow: FinancialStatementLocation = Field(
        description="å€‹é«”ç¾é‡‘æµé‡è¡¨"
    )
    important_accounting_items: FinancialStatementLocation = Field(
        description="é‡è¦æœƒè¨ˆé …ç›®æ˜ç´°è¡¨"
    )
    detailed_sections: List[DetailSectionLocation] = Field(
        default_factory=list,
        description="è©³ç´°çš„é™„è¨»ç« ç¯€åˆ—è¡¨æˆ–å…¶ä»–é‡è¦æ˜ç´°ç« ç¯€ï¼Œä¾‹å¦‚ 'é™„è¨»ä¸€'ã€'é ä»˜æ¬¾é …æ˜ç´°è¡¨' åŠå…¶é ç¢¼",
    )


class ReferenceLocationSchema(BaseModel):
    reference_text: str = Field(..., description="è¦æŸ¥æ‰¾çš„å¼•ç”¨æ–‡æœ¬")
    context: str = Field(default="", description="å¼•ç”¨å‡ºç¾çš„ä¸Šä¸‹æ–‡")


class PageReference(BaseModel):
    """é é¢å¼•ç”¨è³‡è¨Š"""

    source_page: int = Field(description="å¼•ç”¨ä¾†æºé é¢")
    referenced_pages: List[int] = Field(description="è¢«å¼•ç”¨çš„é é¢åˆ—è¡¨")
    reference_text: str = Field(description="å¼•ç”¨çš„åŸæ–‡")
    reference_type: str = Field(description="å¼•ç”¨é¡å‹ï¼šé™„è¨»ã€æ˜ç´°è¡¨ã€èªªæ˜ç­‰")


class ReferenceAnalysisResult(BaseModel):
    """å¼•ç”¨åˆ†æçµæœ"""

    has_references: bool = Field(description="æ˜¯å¦ç™¼ç¾å¼•ç”¨")
    references: List[PageReference] = Field(
        default_factory=list, description="ç™¼ç¾çš„å¼•ç”¨åˆ—è¡¨"
    )
    additional_pages_needed: List[int] = Field(
        default_factory=list, description="éœ€è¦é¡å¤–æå–çš„é é¢"
    )
    notes: Optional[str] = Field(default=None, description="åˆ†æå‚™è¨»")


class DataValidationResult(BaseModel):
    is_valid: bool = Field(description="æ˜¯å¦é©—è­‰æˆåŠŸ")
    errors: List[str] = Field(default_factory=list, description="é©—è­‰éŒ¯èª¤åˆ—è¡¨")
    warnings: List[str] = Field(default_factory=list, description="é©—è­‰è­¦å‘Šåˆ—è¡¨")
    confidence_score: float = Field(description="é©—è­‰ä¿¡å¿ƒåˆ†æ•¸ï¼Œ0-1 ä¹‹é–“")
    notes: Optional[str] = Field(default=None, description="é©—è­‰å‚™è¨»")


class PDFPageExtractionSchema(BaseModel):
    pdf_path: str = Field(..., description="PDF æª”æ¡ˆè·¯å¾‘")
    page_numbers: Optional[List[int]] = Field(
        default=None, description="è¦æ“·å–çš„é é¢ï¼ˆ1-basedï¼‰"
    )
    first_n_pages: Optional[int] = Field(
        default=None, description="è‹¥æœªæŒ‡å®š page_numbersï¼Œæ“·å–å‰ N é "
    )


class TOCAnalysisSchema(BaseModel):
    pass


class FinancialDataExtractionSchema(BaseModel):
    model_name: str = Field(..., description="è¦æå–çš„è²¡å‹™æ¨¡å‹åç¨±")
    page_mapping: str = Field(default="", description="é é¢æ˜ å°„ä¿¡æ¯ï¼ˆå¯é¸ï¼‰")


class DataValidationSchema(BaseModel):
    extracted_data: str = Field(..., description="æå–çš„æ•¸æ“š JSON å­—ä¸²")
    model_name: str = Field(..., description="æ¨¡å‹åç¨±")


# ===============================
# å·¥å…·è¼”åŠ©å‡½æ•¸
# ===============================


class CustomLogCallbackHandler(BaseCallbackHandler):
    """è‡ªå®šç¾©æ—¥èªŒå›èª¿è™•ç†å™¨ï¼Œé¿å…æ‰“å°éé•·çš„ base64 å…§å®¹"""

    def __init__(self):
        super().__init__()
        self.max_content_length = 200  # æœ€å¤§é¡¯ç¤ºé•·åº¦

    def on_tool_start(self, serialized, input_str, **kwargs):
        """å·¥å…·é–‹å§‹æ™‚çš„å›èª¿"""
        tool_name = serialized.get("name", "Unknown Tool")
        print(f"\nğŸ”§ æ­£åœ¨åŸ·è¡Œå·¥å…·: {tool_name}")

        # è™•ç†è¼¸å…¥åƒæ•¸çš„é¡¯ç¤º
        if isinstance(input_str, dict):
            clean_input = {}
            for key, value in input_str.items():
                if isinstance(value, str) and len(value) > self.max_content_length:
                    if "base64" in key.lower():
                        clean_input[key] = f"[BASE64_DATA_{len(value)}_CHARS]"
                    else:
                        clean_input[key] = value[: self.max_content_length] + "..."
                else:
                    clean_input[key] = value
            print(f"   è¼¸å…¥åƒæ•¸: {clean_input}")
        else:
            if isinstance(input_str, str) and len(input_str) > self.max_content_length:
                print(f"   è¼¸å…¥: {input_str[:self.max_content_length]}...")
            else:
                print(f"   è¼¸å…¥: {input_str}")

    def on_tool_end(self, output, **kwargs):
        """å·¥å…·çµæŸæ™‚çš„å›èª¿"""
        if isinstance(output, str):
            try:
                import json

                output_data = json.loads(output)
                # è™•ç† base64 å…§å®¹
                if "base64_content" in output_data:
                    base64_length = len(output_data["base64_content"])
                    output_data["base64_content"] = (
                        f"[BASE64_DATA_{base64_length}_CHARS]"
                    )
                print(f"âœ… å·¥å…·åŸ·è¡Œå®Œæˆ")
                print(
                    f"   è¼¸å‡º: {json.dumps(output_data, ensure_ascii=False, indent=2)}"
                )
            except:
                # å¦‚æœä¸æ˜¯ JSONï¼Œå‰‡ç›´æ¥æˆªæ–·é¡¯ç¤º
                if len(output) > self.max_content_length:
                    print(f"âœ… å·¥å…·åŸ·è¡Œå®Œæˆ")
                    print(f"   è¼¸å‡º: {output[:self.max_content_length]}...")
                else:
                    print(f"âœ… å·¥å…·åŸ·è¡Œå®Œæˆ")
                    print(f"   è¼¸å‡º: {output}")
        else:
            print(f"âœ… å·¥å…·åŸ·è¡Œå®Œæˆ")
            print(f"   è¼¸å‡º: {output}")

    def on_tool_error(self, error, **kwargs):
        """å·¥å…·å‡ºéŒ¯æ™‚çš„å›èª¿"""
        print(f"âŒ å·¥å…·åŸ·è¡Œå‡ºéŒ¯: {error}")

    def on_agent_action(self, action, **kwargs):
        """Agent è¡Œå‹•æ™‚çš„å›èª¿"""
        print(f"\nğŸ¤– Agent æ±ºå®š: {action.log}")

    def on_agent_finish(self, finish, **kwargs):
        """Agent å®Œæˆæ™‚çš„å›èª¿"""
        print(f"\nğŸ¯ Agent å®Œæˆ: {finish.log}")


def setup_genai_client() -> Client:
    """è¨­å®š Gemini API å®¢æˆ¶ç«¯çš„è¼”åŠ©å‡½æ•¸"""
    api_key = os.getenv("GEMINI_API_KEY")
    if not api_key:
        raise ValueError("è«‹è¨­å®š GEMINI_API_KEY ç’°å¢ƒè®Šæ•¸")

    return Client(api_key=api_key)


# ===============================
# LangChain Tools å®šç¾©
# ===============================


class PDFPageExtractionTool(BaseTool):
    """PDF é é¢æå–å·¥å…·"""

    name: str = "pdf_page_extraction"
    description: str = (
        "å¾ PDF æ–‡ä»¶ä¸­æå–æŒ‡å®šé é¢ä¸¦è½‰æ›ç‚º base64 ç·¨ç¢¼ã€‚å¯ä»¥æå–å‰å¹¾é ç”¨æ–¼åˆå§‹åˆ†æï¼Œæˆ–æå–ç‰¹å®šé é¢ã€‚"
        "**æ­¤å·¥å…·æœƒå°‡è«‹æ±‚çš„é é¢èˆ‡å…ˆå‰å·²æå–çš„é é¢åˆä½µï¼Œä¸¦æ›´æ–° Agent ç‹€æ…‹ä¸­çš„æ‰€æœ‰é é¢å…§å®¹ã€‚**"
    )
    args_schema: Type[BaseModel] = PDFPageExtractionSchema
    # æ–°å¢ä¸€å€‹å±¬æ€§ä¾†æ¥æ”¶ Agent çš„ç‹€æ…‹å°è±¡
    agent_state: Optional[PDFProcessingState] = Field(default=None, exclude=True)

    def __init__(self, agent_state: Optional[PDFProcessingState] = None):
        super().__init__()
        self.agent_state = agent_state  # æ¥æ”¶ agent_state

    def _run(
        self,
        pdf_path: str,
        page_numbers: Optional[List[int]] = None,
        first_n_pages: Optional[int] = None,
    ) -> str:
        """
        æå– PDF é é¢

        Args:
            pdf_path: PDF æª”æ¡ˆè·¯å¾‘
            page_numbers: è¦æå–çš„é é¢åˆ—è¡¨ï¼ˆ1-basedï¼‰ï¼Œå¦‚æœç‚ºç©ºå‰‡æå–å‰å¹¾é 
            first_n_pages: æå–å‰å¹¾é ï¼Œé è¨­ç‚º 5
        """
        try:
            if page_numbers is None and first_n_pages is None:
                first_n_pages = 5

            with open(pdf_path, "rb") as file:
                pdf_reader = PyPDF2.PdfReader(file)
                total_pages = len(pdf_reader.pages)

                # ç²å–ç›®å‰å·²æå–çš„é é¢ï¼Œå¦‚æœæ²’æœ‰å‰‡åˆå§‹åŒ–
                current_extracted_pages_set = set(self.agent_state.pages_extracted)

                # ç¢ºå®šæœ¬æ¬¡è¦æ–°å¢çš„é é¢
                pages_to_add_this_run = set()
                if page_numbers:
                    pages_to_add_this_run.update(page_numbers)
                elif first_n_pages is not None and not current_extracted_pages_set:
                    # åªæœ‰åœ¨åˆæ¬¡æå–ä¸”æ²’æœ‰æŒ‡å®šç‰¹å®šé é¢æ™‚æ‰ä½¿ç”¨ first_n_pages
                    pages_to_add_this_run.update(
                        range(1, min(first_n_pages, total_pages) + 1)
                    )
                else:
                    # å¦‚æœæ²’æœ‰æŒ‡å®š page_numbers ä¸”ä¸æ˜¯åˆæ¬¡æå–ï¼Œå‰‡æœ¬æ¬¡æ²’æœ‰æ–°é é¢è¦åŠ 
                    pass

                # åˆä½µæ‰€æœ‰è¦æå–çš„ç¨ç‰¹é é¢
                all_pages_to_extract_set = current_extracted_pages_set.union(
                    pages_to_add_this_run
                )
                all_pages_to_extract_list = sorted(list(all_pages_to_extract_set))

                if not all_pages_to_extract_list:
                    return json.dumps(
                        {
                            "success": False,
                            "error": "æ²’æœ‰é é¢è¢«æŒ‡å®šæˆ–å·²æå–ï¼Œç„¡æ³•å‰µå»º PDF å…§å®¹ã€‚",
                        }
                    )

                pdf_writer = PyPDF2.PdfWriter()
                actual_extracted_pages = []
                for page_num in all_pages_to_extract_list:
                    if 1 <= page_num <= total_pages:
                        pdf_writer.add_page(pdf_reader.pages[page_num - 1])
                        actual_extracted_pages.append(page_num)
                    else:
                        print(
                            f"è­¦å‘Šï¼šé ç¢¼ {page_num} è¶…å‡ºæ–‡ä»¶ç¯„åœ (1-{total_pages})ï¼Œå·²è·³éã€‚"
                        )
                        self.agent_state.errors.append(
                            f"æå–é é¢ {page_num} è¶…å‡ºç¯„åœã€‚"
                        )

                # è½‰æ›ç‚º base64
                output_buffer = io.BytesIO()
                pdf_writer.write(output_buffer)
                pdf_bytes = output_buffer.getvalue()
                base64_encoded = base64.b64encode(pdf_bytes).decode("utf-8")

                self.agent_state.all_pages_base64 = base64_encoded
                self.agent_state.pages_extracted = (
                    actual_extracted_pages  # æ›´æ–°ç‚ºå¯¦éš›æå–çš„é é¢åˆ—è¡¨
                )
                self.agent_state.current_step = (
                    f"å·²æå–PDFé é¢ {actual_extracted_pages}"
                )

                result = {
                    "success": True,
                    "extracted_pages": actual_extracted_pages,
                    "newly_added_pages": sorted(
                        list(
                            pages_to_add_this_run.difference(
                                current_extracted_pages_set
                            )
                        )
                    ),
                    "base64_length": len(base64_encoded),
                    "message": f"æˆåŠŸæå–ä¸¦åˆä½µé é¢ {actual_extracted_pages}ã€‚Base64 å…§å®¹å·²å­˜å„²åœ¨ Agent ç‹€æ…‹ä¸­ï¼Œé•·åº¦: {len(base64_encoded):,} å­—ç¬¦ã€‚",
                    "next_action_hint": "ç¾åœ¨å¯ä»¥æ ¹æ“šéœ€æ±‚ï¼Œå‘¼å« toc_analysis æˆ– reference_detection å·¥å…·ã€‚",
                }

                return json.dumps(result)

        except Exception as e:
            return json.dumps(
                {
                    "success": False,
                    "error": str(e),
                    "message": f"æå–é é¢æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}",
                }
            )


class TOCAnalysisTool(BaseTool):
    """ç›®éŒ„åˆ†æå·¥å…·"""

    name: str = "toc_analysis"
    description: str = (
        "åˆ†æ PDF çš„å‰å¹¾é ï¼Œæ‰¾å‡ºç›®éŒ„é ä½ç½®ï¼Œç„¶å¾Œåˆ†æç›®éŒ„å…§å®¹æ‰¾å‡ºå„è²¡å‹™å ±è¡¨çš„é æ•¸ä½ç½®ã€‚"
    )
    args_schema: Type[BaseModel] = TOCAnalysisSchema

    genai_client: Client = Field(..., exclude=True)
    agent_state: Optional[PDFProcessingState] = Field(default=None, exclude=True)

    def __init__(
        self, genai_client: Client, agent_state: Optional[PDFProcessingState] = None
    ):
        super().__init__(genai_client=genai_client)
        self.genai_client = genai_client
        self.agent_state = agent_state

    def _run(self) -> str:
        """
        åˆ†æç›®éŒ„ä¸¦æ‰¾å‡ºè²¡å‹™å ±è¡¨ä½ç½®

        Args:
            base64_pdf: PDF çš„ base64 ç·¨ç¢¼å…§å®¹ï¼ˆé€šå¸¸æ˜¯å‰å¹¾é ï¼‰
        """
        try:
            if not self.agent_state or not self.agent_state.all_pages_base64:
                return json.dumps(
                    {
                        "success": False,
                        "error": "PDF Base64 å…§å®¹æœªåœ¨ Agent ç‹€æ…‹ä¸­æ‰¾åˆ°ã€‚",
                        "message": "è«‹ç¢ºä¿å·²é‹è¡Œ pdf_page_extraction å·¥å…·ä¸¦æˆåŠŸå­˜å„²å…§å®¹ã€‚",
                    }
                )

            base64_pdf = (
                self.agent_state.all_pages_base64
            )  # å¾ Agent ç‹€æ…‹ä¸­ç²å– PDF å…§å®¹
            self.agent_state.current_step = "æ­£åœ¨åˆ†æç›®éŒ„é "
            # ç¬¬ä¸€æ­¥ï¼šæ‰¾åˆ°ç›®éŒ„é 
            toc_prompt = """
            è«‹åˆ†æé€™å€‹PDFæ–‡ä»¶çš„å‰å¹¾é ï¼Œæ‰¾å‡ºç›®éŒ„é ï¼ˆTable of Contentsï¼‰çš„ä½ç½®ã€‚

            è«‹å‘Šè¨´æˆ‘ï¼š
            1. æ˜¯å¦æœ‰ç›®éŒ„é ï¼Ÿ
            2. å¦‚æœæœ‰ï¼Œç›®éŒ„é åœ¨ç¬¬å¹¾é ï¼Ÿï¼ˆå¯èƒ½æœ‰å¤šé ï¼‰

            æ³¨æ„ï¼šç›®éŒ„é é€šå¸¸åŒ…å«ç« ç¯€æ¨™é¡Œå’Œå°æ‡‰çš„é æ•¸ã€‚
            """

            pdf_part = {
                "inline_data": {"mime_type": "application/pdf", "data": base64_pdf}
            }
            # æ‰¾ç›®éŒ„é ä½ç½®
            toc_response = self.genai_client.models.generate_content(
                model="gemini-2.5-flash-preview-05-20",
                contents=[toc_prompt, pdf_part],
                config={
                    "response_mime_type": "application/json",
                    "response_schema": TableOfContentsInfo,
                },
            )

            # ç¬¬äºŒæ­¥ï¼šåˆ†æç›®éŒ„å…§å®¹æ‰¾è²¡å‹™å ±è¡¨
            analysis_prompt = """
            è«‹åˆ†æé€™å€‹PDFçš„ç›®éŒ„é ï¼Œæ‰¾å‡ºä»¥ä¸‹è²¡å‹™å ±è¡¨é …ç›®åœ¨ç›®éŒ„ä¸­é¡¯ç¤ºçš„é æ•¸ï¼š

            1. å€‹é«”è³‡ç”¢è² å‚µè¡¨
            2. å€‹é«”ç¶œåˆæç›Šè¡¨  
            3. å€‹é«”æ¬Šç›Šè®Šå‹•è¡¨
            4. å€‹é«”ç¾é‡‘æµé‡è¡¨
            5. é‡è¦æœƒè¨ˆé …ç›®æ˜ç´°è¡¨

            è«‹ä»”ç´°æŸ¥çœ‹ç›®éŒ„ä¸­çš„é …ç›®åç¨±ï¼Œå¯èƒ½æœƒæœ‰é¡ä¼¼çš„è¡¨é”æ–¹å¼ï¼Œä¾‹å¦‚ï¼š
            - "è³‡ç”¢è² å‚µè¡¨"ã€"Balance Sheet"
            - "ç¶œåˆæç›Šè¡¨"ã€"Comprehensive Income Statement"
            - "æ¬Šç›Šè®Šå‹•è¡¨"ã€"Statement of Changes in Equity"
            - "ç¾é‡‘æµé‡è¡¨"ã€"Cash Flow Statement"
            - "é‡è¦æœƒè¨ˆé …ç›®æ˜ç´°è¡¨"ã€"Notes to Financial Statements"ã€"é™„è¨»"

            æ³¨æ„ï¼š
            - è«‹æ ¹æ“šç›®éŒ„ä¸­é¡¯ç¤ºçš„é æ•¸å¡«å¯«
            - å¦‚æœæ‰¾ä¸åˆ°æŸå€‹é …ç›®ï¼Œè«‹å°‡foundè¨­ç‚ºfalse
            - å¦‚æœæŸå€‹å ±è¡¨è·¨è¶Šå¤šé ï¼Œè«‹åˆ—å‡ºæ‰€æœ‰ç›¸é—œé æ•¸
            - é‡è¦æœƒè¨ˆé …ç›®æ˜ç´°è¡¨ä¸ç­‰æ–¼é‡è¦æœƒè¨ˆé …ç›®ä¹‹èªªæ˜ï¼Œè«‹æ³¨æ„å€åˆ†
            """

            analysis_response = self.genai_client.models.generate_content(
                model="gemini-2.5-flash-preview-05-20",
                contents=[analysis_prompt, pdf_part],
                config={
                    "response_mime_type": "application/json",
                    "response_schema": FinancialStatementsAnalysis,
                },
            )

            # è§£æçµæœ
            toc_result = toc_response.parsed
            analysis_result = analysis_response.parsed

            return json.dumps(
                {
                    "success": True,
                    "toc_analysis": toc_result.model_dump(),
                    "financial_statements": analysis_result.model_dump(),
                    "message": "ç›®éŒ„åˆ†æå®Œæˆ",
                }
            )

        except Exception as e:
            return json.dumps(
                {
                    "success": False,
                    "error": str(e),
                    "message": f"ç›®éŒ„åˆ†ææ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}",
                }
            )

            # class ReferenceDetectionTool(BaseTool):
            #     """é é¢å¼•ç”¨æª¢æ¸¬å·¥å…·"""

            #     name: str = "reference_detection"
            #     description: str = (
            #         "æª¢æ¸¬ PDF é é¢ä¸­çš„äº¤å‰å¼•ç”¨ï¼Œæ‰¾å‡ºéœ€è¦é¡å¤–æå–çš„é é¢ã€‚èƒ½è­˜åˆ¥é™„è¨»å¼•ç”¨ã€é é¢å¼•ç”¨ç­‰ã€‚"
            #     )

            #     # æ­£ç¢ºè²æ˜å±¬æ€§
            #     genai_client: Client = Field(..., exclude=True)
            #     args_schema: Type[BaseModel] = ReferenceDetectionSchema
            #     agent_state: Optional[PDFProcessingState] = Field(default=None, exclude=True)

            #     def __init__(
            #         self, genai_client: Client, agent_state: Optional[PDFProcessingState] = None
            #     ):
            #         super().__init__(genai_client=genai_client)
            #         self.genai_client = genai_client
            #         self.agent_state = agent_state

            #     def _run(self, current_pages: str) -> str:
            #         """
            #         æª¢æ¸¬é é¢å¼•ç”¨

            #         Args:
            #             base64_pdf: PDF çš„ base64 ç·¨ç¢¼å…§å®¹
            #             current_pages: ç•¶å‰å·²æå–çš„é é¢åˆ—è¡¨ï¼Œæ ¼å¼ç‚º "1,2,3"
            #         """
            #         try:
            #             # è§£æé é¢åˆ—è¡¨
            #             if current_pages.startswith("[") and current_pages.endswith("]"):
            #                 current_pages = current_pages[1:-1]
            #             current_pages_list = [
            #                 int(x.strip()) for x in current_pages.split(",") if x.strip()
            #             ]

            #             prompt = f"""
            #             è«‹ä»”ç´°åˆ†æé€™äº›PDFé é¢ä¸­çš„æ–‡å­—å…§å®¹ï¼Œæ‰¾å‡ºæ‰€æœ‰æåˆ°å…¶ä»–é é¢çš„å¼•ç”¨ã€‚

            #             ç•¶å‰åˆ†æçš„é é¢ç¯„åœï¼š{current_pages_list}

            #             è«‹ç‰¹åˆ¥æ³¨æ„ä»¥ä¸‹é¡å‹çš„å¼•ç”¨ï¼š
            #             1. é™„è¨»å¼•ç”¨ï¼šã€Œé™„è¨»Xã€ã€ã€Œè©³è¦‹é™„è¨»Xã€ã€ã€ŒNote Xã€
            #             2. é é¢å¼•ç”¨ï¼šã€Œç¬¬Xé ã€ã€ã€Œè¦‹ç¬¬Xé ã€ã€ã€ŒPage Xã€
            #             3. æ˜ç´°è¡¨å¼•ç”¨ï¼šã€Œæ˜ç´°è¡¨ã€ã€ã€Œè©³ç´°è³‡æ–™ã€ã€ã€Œbreakdownã€
            #             4. æœƒè¨ˆæ”¿ç­–å¼•ç”¨ï¼šã€Œæœƒè¨ˆæ”¿ç­–èªªæ˜ã€ã€ã€Œé‡è¦æœƒè¨ˆé …ç›®ä¹‹èªªæ˜ã€

            #             æ³¨æ„ï¼š
            #             - è«‹åªæå–æ˜ç¢ºæåˆ°å…·é«”é é¢æ•¸å­—çš„å¼•ç”¨
            #             - å¦‚æœå¼•ç”¨çš„é é¢å·²ç¶“åœ¨ç•¶å‰é é¢ç¯„åœå…§ï¼Œä¸éœ€è¦åˆ—ç‚ºé¡å¤–éœ€è¦çš„é é¢
            #             """

            #             base64_pdf = (
            #                 self.agent_state.all_pages_base64
            #             )  # å¾ Agent ç‹€æ…‹ä¸­ç²å– PDF å…§å®¹
            #             self.agent_state.current_step = "æ­£åœ¨åˆ†æé é¢å¼•ç”¨"
            #             pdf_part = {
            #                 "inline_data": {"mime_type": "application/pdf", "data": base64_pdf}
            #             }

            #             response = self.genai_client.models.generate_content(
            #                 model="gemini-2.5-flash-preview-05-20",
            #                 contents=[prompt, pdf_part],
            #                 config={
            #                     "response_mime_type": "application/json",
            #                     "response_schema": ReferenceAnalysisResult,
            #                 },
            #             )

            #             # è§£æçµæœ
            #             reference_result = response.parsed

            #             return json.dumps(
            #                 {
            #                     "success": True,
            #                     "reference_analysis": reference_result.model_dump(),
            #                     "message": f"å¼•ç”¨æª¢æ¸¬å®Œæˆï¼Œç™¼ç¾ {len(reference_result.get('references', []))} å€‹å¼•ç”¨",
            #                 }
            #             )

            #         except Exception as e:
            return json.dumps(
                {
                    "success": False,
                    "error": str(e),
                    "message": f"å¼•ç”¨æª¢æ¸¬æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}",
                }
            )


class ReferenceLocationTool(BaseTool):
    """æ ¹æ“šå¼•ç”¨æ–‡æœ¬åœ¨ç›®éŒ„ä¸­æŸ¥æ‰¾å°æ‡‰é é¢çš„å·¥å…·"""

    name: str = "reference_location_lookup"
    description: str = (
        "æ ¹æ“šåœ¨è²¡å‹™æ•¸æ“šæå–éç¨‹ä¸­ç™¼ç¾çš„å¼•ç”¨æ–‡æœ¬ï¼ˆå¦‚'é™„è¨»å…­'ã€'æ˜ç´°è¡¨'ç­‰ï¼‰ï¼Œ"
        "åœ¨å·²åˆ†æçš„ç›®éŒ„ä¸­æŸ¥æ‰¾å°æ‡‰çš„é é¢ä½ç½®ã€‚"
    )

    genai_client: Client = Field(..., exclude=True)
    args_schema: Type[BaseModel] = ReferenceLocationSchema
    agent_state: Optional[PDFProcessingState] = Field(default=None, exclude=True)

    def __init__(
        self, genai_client: Client, agent_state: Optional[PDFProcessingState] = None
    ):
        super().__init__(genai_client=genai_client)
        self.genai_client = genai_client
        self.agent_state = agent_state

    def _run(self, reference_text: str, context: str = "") -> str:
        """
        åœ¨ç›®éŒ„ä¸­æŸ¥æ‰¾å¼•ç”¨å°æ‡‰çš„é é¢

        Args:
            reference_text: å¼•ç”¨æ–‡æœ¬ï¼Œå¦‚ "é™„è¨»å…­"ã€"ç¾é‡‘åŠç´„ç•¶ç¾é‡‘æ˜ç´°è¡¨"
            context: å¼•ç”¨å‡ºç¾çš„ä¸Šä¸‹æ–‡ï¼Œå¹«åŠ©æ›´æº–ç¢ºå®šä½
        """
        try:
            if not self.agent_state or not self.agent_state.toc_analysis_result:
                return json.dumps(
                    {
                        "success": False,
                        "error": "ç›®éŒ„åˆ†æçµæœæœªæ‰¾åˆ°ï¼Œè«‹å…ˆåŸ·è¡Œç›®éŒ„åˆ†æã€‚",
                    }
                )

            # ä½¿ç”¨ç›®éŒ„é é¢å…§å®¹é€²è¡ŒæŸ¥æ‰¾
            base64_pdf = self.agent_state.all_pages_base64
            self.agent_state.current_step = f"æ­£åœ¨æŸ¥æ‰¾å¼•ç”¨: {reference_text}"

            lookup_prompt = f"""
            æ ¹æ“šä»¥ä¸‹å¼•ç”¨æ–‡æœ¬ï¼Œåœ¨é€™å€‹PDFçš„ç›®éŒ„ä¸­æŸ¥æ‰¾å°æ‡‰çš„é é¢ä½ç½®ï¼š
            
            å¼•ç”¨æ–‡æœ¬ï¼š{reference_text}
            ä¸Šä¸‹æ–‡ï¼š{context}
            
            è«‹åœ¨ç›®éŒ„ä¸­æŸ¥æ‰¾å¯èƒ½å°æ‡‰çš„ç« ç¯€ï¼Œèˆ‰ä¾‹ï¼š
            - "ç¾é‡‘åŠç´„ç•¶ç¾é‡‘(é™„è¨»å…­)" å¯èƒ½å°æ‡‰ç›®éŒ„ä¸­ "å€‹é«”è²¡å‹™å ±å‘Šé™„è¨»(å…­)"æˆ–é¡ä¼¼ç« ç¯€
            
            è«‹æä¾›ï¼š
            1. æ˜¯å¦åœ¨ç›®éŒ„ä¸­æ‰¾åˆ°å°æ‡‰ç« ç¯€
            2. å°æ‡‰çš„ç« ç¯€åç¨±
            3. è©²ç« ç¯€çš„é é¢ç¯„åœ
            4. æŸ¥æ‰¾çš„ä¿¡å¿ƒåˆ†æ•¸ï¼ˆ0-1ï¼‰
            
            æ³¨æ„ï¼šè¦ä»”ç´°æ¯”å°å¼•ç”¨æ–‡æœ¬èˆ‡ç›®éŒ„ä¸­çš„ç« ç¯€æ¨™é¡Œã€‚
            """

            pdf_part = {
                "inline_data": {"mime_type": "application/pdf", "data": base64_pdf}
            }

            response = self.genai_client.models.generate_content(
                model="gemini-2.5-flash-preview-05-20",
                contents=[lookup_prompt, pdf_part],
                config={
                    "response_mime_type": "application/json",
                    "response_schema": ReferenceLocationResult,
                },
            )

            result = response.parsed

            return json.dumps(
                {
                    "success": True,
                    "reference_lookup": result.model_dump(),
                    "message": f"å¼•ç”¨æŸ¥æ‰¾å®Œæˆ: {reference_text}",
                }
            )

        except Exception as e:
            return json.dumps(
                {
                    "success": False,
                    "error": str(e),
                    "message": f"æŸ¥æ‰¾å¼•ç”¨ {reference_text} æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}",
                }
            )


class EnhancedFinancialDataExtractionTool(BaseTool):
    """å¢å¼·ç‰ˆè²¡å‹™æ•¸æ“šæå–å·¥å…· - æ”¯æ´å¼•ç”¨ç™¼ç¾å’Œå›å ±"""

    name: str = "enhanced_financial_data_extraction"
    description: str = (
        "å¾è²¡å‹™å ±è¡¨é é¢ä¸­æå–çµæ§‹åŒ–çš„è²¡å‹™æ•¸æ“šï¼Œä¸¦åœ¨æå–éç¨‹ä¸­ä¸»å‹•ç™¼ç¾å’Œå›å ±å¼•ç”¨ã€‚"
        "å¦‚æœç™¼ç¾æ•¸æ“šä¸å®Œæ•´æˆ–æœ‰å¼•ç”¨åˆ°å…¶ä»–é é¢ï¼Œæœƒè¿”å›ç™¼ç¾çš„å¼•ç”¨ä¿¡æ¯ã€‚"
    )

    genai_client: Client = Field(..., exclude=True)
    models_config: Dict[str, Any] = Field(default_factory=dict, exclude=True)
    args_schema: Type[BaseModel] = FinancialDataExtractionSchema
    agent_state: Optional[PDFProcessingState] = Field(default=None, exclude=True)

    def __init__(
        self, genai_client: Client, agent_state: Optional[PDFProcessingState] = None
    ):
        super().__init__(genai_client=genai_client, models_config={})
        self.genai_client = genai_client
        self.agent_state = agent_state

        # è²¡å‹™æ¨¡å‹é…ç½®
        self.models_config = {
            "ç¾é‡‘åŠç´„ç•¶ç¾é‡‘": {
                "model_class": CashAndEquivalents,
                "prompt": cash_equivalents_prompt,
            },
            "é ä»˜æ¬¾é …": {
                "model_class": PrePayments,
                "prompt": prepayments_prompt,
            },
            "æ‡‰æ”¶é—œä¿‚äººæ¬¾é …": {
                "model_class": ReceivablesRelatedParties,
                "prompt": receivables_related_parties_prompt,
            },
            "è² å‚µç¸½é¡": {
                "model_class": TotalLiabilities,
                "prompt": total_liabilities_prompt,
            },
        }

    def _run(self, model_name: str, page_mapping: str = "") -> str:
        """
        æå–ç‰¹å®šè²¡å‹™æ•¸æ“šä¸¦ç™¼ç¾å¼•ç”¨

        Args:
            model_name: è¦æå–çš„è²¡å‹™æ¨¡å‹åç¨±
            page_mapping: é é¢æ˜ å°„ä¿¡æ¯ï¼ˆå¯é¸ï¼‰
        """
        try:
            if model_name not in self.models_config:
                return json.dumps(
                    {
                        "success": False,
                        "error": f"ä¸æ”¯æ´çš„æ¨¡å‹åç¨±: {model_name}",
                        "message": f"æ”¯æ´çš„æ¨¡å‹: {list(self.models_config.keys())}",
                    }
                )

            config = self.models_config[model_name]

            # ä¿®æ”¹æç¤ºè©ï¼ŒåŠ å…¥å¼•ç”¨ç™¼ç¾æŒ‡ä»¤
            enhanced_prompt = f"""
            å°‡æå–çš„æ•¸æ“šè¨˜éŒ„åœ¨ extracted_data ä¸­ã€‚
            {config["prompt"]}
            
            **é‡è¦è£œå……æŒ‡ä»¤ï¼šåœ¨æå–æ•¸æ“šçš„éç¨‹ä¸­ï¼Œè«‹ç‰¹åˆ¥æ³¨æ„ä»¥ä¸‹æƒ…æ³ï¼š**
            
            1. **å¼•ç”¨ç™¼ç¾**ï¼šå¦‚æœåœ¨ç•¶å‰é é¢ä¸­çœ‹åˆ°ä»»ä½•å¼•ç”¨å…¶ä»–é æ•¸çš„æ–‡å­—ï¼Œå¦‚ï¼š
               - "è©³è¦‹é™„è¨»X"
               - "è¦‹ç¬¬Xé æ˜ç´°è¡¨"  
               - "åƒè€ƒé™„è¨»èªªæ˜"
               - "æ˜ç´°å¦‚ä¸‹è¡¨"
               è«‹å°‡é€™äº›å¼•ç”¨è¨˜éŒ„ä¸‹ä¾†ã€‚
               å¦‚æœè©²å¼•ç”¨å°±åœ¨åŒä¸€é ï¼Œå‰‡ä¸éœ€è¨˜éŒ„ã€‚
            
            2. **æ•¸æ“šå®Œæ•´æ€§è©•ä¼°**ï¼š  
                - è‹¥åœ¨ç•¶å‰é é¢çœ‹åˆ°ã€Œè©³è¦‹é™„è¨»Xã€ã€ã€Œè¦‹ç¬¬Xé æ˜ç´°è¡¨ã€ã€ã€Œå¦‚æ˜ç´°è¡¨æ‰€ç¤ºã€ç­‰åƒç…§æ–‡å­—ï¼Œ
                  æˆ–è©²æ¬„ä½æ—æ˜ç¢ºé¡¯ç¤ºéœ€è¦æŸ¥çœ‹å…¶ä»–é é¢æ‰èƒ½å–å¾—æ•¸å€¼ï¼Œè«‹æ¨™è¨˜ç‚º **ä¸å®Œæ•´**ï¼Œä¸¦èªªæ˜ç¼ºå¤±åŸå› ã€‚  
                - å¦‚æœè©²è¡¨æ ¼æ ¹æœ¬æ²’æœ‰åˆ—å‡ºæŸäº›å­æ¬„ä½ï¼ˆä¾‹å¦‚é›¶ç”¨é‡‘ã€å¾…äº¤æ›ç¥¨æ“šã€å•†æ¥­æœ¬ç¥¨ç­‰ï¼‰ï¼Œä¸”ä¹Ÿæ²’æœ‰ä»»ä½•ã€Œè©³è¦‹é™„è¨»ã€å­—æ¨£ï¼Œ
                  å°± **ç›´æ¥å¡«å…¥ null**ï¼Œä½†é€™ä¸è¦–ç‚ºè³‡æ–™ä¸å®Œæ•´ï¼Œå› ç‚ºæœ¬ä¾†å°±ä¸å­˜åœ¨è©²è³‡è¨Šã€‚  

            
            3. **è¿”å›æ ¼å¼**ï¼šé™¤äº† extracted_data å¤–ï¼Œé‚„éœ€è¦åŒ…å«ï¼š
               - discovered_references: ç™¼ç¾çš„å¼•ç”¨åˆ—è¡¨
               - is_complete: æ•¸æ“šæ˜¯å¦å®Œæ•´
               - missing_info_description: å¦‚æœä¸å®Œæ•´ï¼Œæè¿°ç¼ºå¤±çš„ä¿¡æ¯
            
            æ³¨æ„äº‹é …
               - å¦‚æœæŸå€‹å­æ¬„ä½å®Œå…¨æ²’æœ‰å‡ºç¾ï¼Œä¹Ÿæ²’å‡ºç¾ä»»ä½•åƒç…§æ–‡å­—ï¼Œå°±è«‹å›å‚³ `"è©²æ¬„ä½": null`ï¼Œä¸¦ä¸” `is_complete: True`ã€‚
            """

            # æº–å‚™ç³»çµ±æç¤º
            system_hint = ""
            if page_mapping:
                system_hint = f"âš ï¸ **é ç¢¼å°ç…§æé†’**ï¼š{page_mapping}"

            if system_hint:
                enhanced_prompt = system_hint + "\n\n" + enhanced_prompt

            base64_pdf = self.agent_state.all_pages_base64
            self.agent_state.current_step = f"æ­£åœ¨æå– {model_name} æ•¸æ“šä¸¦æª¢æ¸¬å¼•ç”¨"

            pdf_part = {
                "inline_data": {"mime_type": "application/pdf", "data": base64_pdf}
            }

            # ç™¼é€è«‹æ±‚ - ä½¿ç”¨æ–°çš„å›æ‡‰çµæ§‹
            response = self.genai_client.models.generate_content(
                model="gemini-2.5-flash-preview-05-20",
                contents=[enhanced_prompt, pdf_part],
                config={
                    "response_mime_type": "application/json",
                    "response_schema": ExtractionResultWithReferences,
                },
            )

            result = response.parsed
            print(result.model_dump())
            import sys

            # å°‡ç™¼ç¾çš„å¼•ç”¨å­˜å„²åˆ°ç‹€æ…‹ä¸­
            if result.discovered_references and not result.is_complete:
                for ref in result.discovered_references:
                    self.agent_state.discovered_references.append(
                        {
                            "reference_text": ref.reference_text,
                            "reference_type": ref.reference_type,
                            "context": ref.context,
                            "page_numbers": ref.page_numbers,
                        }
                    )

            # å¦‚æœæ•¸æ“šä¸å®Œæ•´ï¼Œè¨˜éŒ„åˆ°ç‹€æ…‹ä¸­
            if not result.is_complete:
                self.agent_state.incomplete_extractions[model_name] = {
                    "extracted_data": result.extracted_data,
                    "missing_info": result.missing_info_description,
                    "references": [
                        ref.model_dump() for ref in result.discovered_references
                    ],
                }

            return json.dumps(
                {
                    "success": True,
                    "model_name": model_name,
                    "extraction_result": result.extracted_data,
                    "has_references": (
                        len(result.discovered_references)
                        if not result.is_complete
                        else 0
                    ),
                    "is_complete": result.is_complete,
                    "message": f"{model_name} æ•¸æ“šæå–å®Œæˆ"
                    + (
                        f"ï¼Œç™¼ç¾ {len(result.discovered_references)} å€‹å¼•ç”¨"
                        if result.discovered_references and not result.is_complete
                        else ""
                    ),
                }
            )

        except Exception as e:
            return json.dumps(
                {
                    "success": False,
                    "error": str(e),
                    "message": f"æå– {model_name} æ•¸æ“šæ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}",
                }
            )


class DataValidationTool(BaseTool):
    """æ•¸æ“šé©—è­‰å·¥å…·"""

    name: str = "data_validation"
    description: str = "é©—è­‰æå–çš„è²¡å‹™æ•¸æ“šæ˜¯å¦æ­£ç¢ºï¼Œæª¢æŸ¥æ•¸å­—æº–ç¢ºæ€§ã€å–®ä½ä¸€è‡´æ€§ç­‰ã€‚"

    # æ­£ç¢ºè²æ˜å±¬æ€§
    genai_client: Client = Field(..., exclude=True)
    args_schema: Type[BaseModel] = DataValidationSchema
    agent_state: Optional[PDFProcessingState] = Field(default=None, exclude=True)

    def __init__(
        self, genai_client: Client, agent_state: Optional[PDFProcessingState] = None
    ):
        super().__init__(genai_client=genai_client)
        self.genai_client = genai_client
        self.agent_state = agent_state

    def _run(self, extracted_data: str, model_name: str) -> str:
        """
        é©—è­‰æå–çš„æ•¸æ“š

        Args:
            base64_pdf: PDF çš„ base64 ç·¨ç¢¼å…§å®¹
            extracted_data: æå–çš„æ•¸æ“š JSON å­—ä¸²
            model_name: æ¨¡å‹åç¨±
        """
        try:
            validation_prompt = f"""
            è«‹ä½ ä½œç‚ºä¸€å€‹åš´æ ¼çš„è²¡å‹™æ•¸æ“šå¯©æ ¸å“¡ï¼Œä»”ç´°æª¢æŸ¥ä»¥ä¸‹æå–çš„ {model_name} æ•¸æ“šæ˜¯å¦æ­£ç¢ºã€‚

            æå–çš„æ•¸æ“šï¼š
            {extracted_data}

            è«‹åŸ·è¡Œä»¥ä¸‹æª¢æŸ¥ï¼š
            1. **æ•¸å­—æº–ç¢ºæ€§æª¢æŸ¥**ï¼šå°æ¯”PDFä¸­çš„åŸå§‹æ•¸å­—èˆ‡æå–çš„æ•¸å­—
            2. **å–®ä½ä¸€è‡´æ€§æª¢æŸ¥**ï¼šæª¢æŸ¥å–®ä½æ˜¯å¦æ­£ç¢º
            3. **é æ•¸å’Œæ¨™ç±¤æª¢æŸ¥**ï¼šé©—è­‰ä¾†æºé é¢å’Œæ¨™ç±¤
            4. **é‚è¼¯ä¸€è‡´æ€§æª¢æŸ¥**ï¼šæª¢æŸ¥æ•¸å­—é–“çš„é‚è¼¯é—œä¿‚
            5. **å®Œæ•´æ€§æª¢æŸ¥**ï¼šç¢ºèªæ‰€æœ‰æ¬„ä½éƒ½æœ‰æ•¸æ“š

            """
            base64_pdf = self.agent_state.all_pages_base64
            self.agent_state.current_step = f"æ­£åœ¨é©—è­‰ {model_name} æ•¸æ“š"
            pdf_part = {
                "inline_data": {"mime_type": "application/pdf", "data": base64_pdf}
            }

            response = self.genai_client.models.generate_content(
                model="gemini-2.5-flash-preview-05-20",
                contents=[validation_prompt, pdf_part],
                config={
                    "response_mime_type": "application/json",
                    "response_schema": DataValidationResult,
                },
            )

            validation_result = response.parsed

            return json.dumps(
                {
                    "success": True,
                    "model_name": model_name,
                    "validation_result": validation_result.model_dump(),
                    "message": f"{model_name} é©—è­‰å®Œæˆ",
                }
            )

        except Exception as e:
            return json.dumps(
                {
                    "success": False,
                    "error": str(e),
                    "message": f"é©—è­‰ {model_name} æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}",
                }
            )


# ===============================
# ä¸»è¦çš„ Agent é¡åˆ¥
# ===============================


class FinancialReportAnalysisAgent:
    """è²¡å‹™å ±è¡¨åˆ†æä¸» Agent"""

    def __init__(self, verbose: bool = False):
        self.verbose = verbose
        self.genai_client = self._setup_genai_client()
        self.llm = self._setup_llm()
        self.state: Optional[PDFProcessingState] = None
        self.tools = []
        self.agent = None

    def _setup_llm(self):
        """è¨­å®šèªè¨€æ¨¡å‹ - ä½¿ç”¨ OpenAI"""
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            raise ValueError("è«‹è¨­å®š OPENAI_API_KEY ç’°å¢ƒè®Šæ•¸")

        return ChatOpenAI(
            model="gpt-4.1-2025-04-14",  # ä½¿ç”¨æ”¯æ´å‡½æ•¸èª¿ç”¨çš„æ¨¡å‹
            api_key=api_key,
            temperature=0,
        )

    def _setup_tools(self, state: PDFProcessingState):
        """è¨­å®šå·¥å…·"""
        return [
            PDFPageExtractionTool(agent_state=state),
            TOCAnalysisTool(genai_client=self.genai_client, agent_state=state),
            EnhancedFinancialDataExtractionTool(
                genai_client=self.genai_client, agent_state=state
            ),  # ä½¿ç”¨å¢å¼·ç‰ˆ
            ReferenceLocationTool(
                genai_client=self.genai_client, agent_state=state
            ),  # æ–°å¢
            DataValidationTool(genai_client=self.genai_client, agent_state=state),
        ]

    def _setup_agent(self):
        """è¨­å®š Agent"""
        prompt = ChatPromptTemplate.from_messages(
            [
                (
                    "system",
                    """ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„è²¡å‹™å ±è¡¨åˆ†æå°ˆå®¶ï¼Œæ“…é•·è§£æ PDF æ ¼å¼çš„è²¡å‹™å ±å‘Šã€‚

                    ä½ çš„ä»»å‹™æ˜¯ï¼š
                    1. åˆ†æ PDF è²¡å‹™å ±è¡¨çš„çµæ§‹ã€‚
                    2. æ‰¾å‡ºå„è²¡å‹™å ±è¡¨çš„é é¢ä½ç½®ã€‚
                    3. **åœ¨æå–è²¡å‹™æ•¸æ“šçš„éç¨‹ä¸­**æª¢æ¸¬å¼•ç”¨ï¼Œä¸¦å‹•æ…‹æŸ¥æ‰¾å’Œæå–é¡å¤–é é¢ã€‚
                    4. æå–å®Œæ•´çš„çµæ§‹åŒ–è²¡å‹™æ•¸æ“šã€‚
                    5. é©—è­‰æå–æ•¸æ“šçš„æº–ç¢ºæ€§ã€‚

                    ä½ æœ‰ä»¥ä¸‹å·¥å…·å¯ä»¥ä½¿ç”¨ï¼š
                    - pdf_page_extraction: æå– PDF é é¢
                    - toc_analysis: åˆ†æç›®éŒ„æ‰¾å‡ºè²¡å‹™å ±è¡¨ä½ç½®  
                    - enhanced_financial_data_extraction: **å¢å¼·ç‰ˆè²¡å‹™æ•¸æ“šæå–ï¼Œæœƒè‡ªå‹•ç™¼ç¾å¼•ç”¨**
                    - reference_location_lookup: **æ ¹æ“šå¼•ç”¨æ–‡æœ¬åœ¨ç›®éŒ„ä¸­æŸ¥æ‰¾å°æ‡‰é é¢**
                    - data_validation: é©—è­‰æ•¸æ“šæº–ç¢ºæ€§

                    è«‹æŒ‰ç…§ä»¥ä¸‹é‚è¼¯é †åºä½¿ç”¨é€™äº›å·¥å…·ï¼Œä¸¦åœ¨æ¯ä¸€æ­¥éƒ½æä¾›æ¸…æ™°çš„èªªæ˜ï¼š

                    1. **åˆå§‹é é¢æå–**: æå–å‰ 5 é é€²è¡Œçµæ§‹åˆ†æã€‚
                    2. **ç›®éŒ„åˆ†æ**: è­˜åˆ¥æ‰€æœ‰ä¸»è¦è²¡å‹™å ±è¡¨çš„é é¢ä½ç½®ã€‚
                    3. **æ ¸å¿ƒå ±è¡¨é é¢æå–**: æå–ç›®éŒ„ä¸­è­˜åˆ¥å‡ºçš„è²¡å‹™å ±è¡¨é é¢ã€‚
                    4. **æ™ºèƒ½è²¡å‹™æ•¸æ“šæå–å¾ªç’°**: å°æ¯å€‹è²¡å‹™æ¨¡å‹åŸ·è¡Œä»¥ä¸‹å¾ªç’°ï¼š
                        a. ä½¿ç”¨ `enhanced_financial_data_extraction` æå–æ•¸æ“š
                        b. **æª¢æŸ¥å›æ‡‰**: å¦‚æœ `has_references: true`ï¼Œè¡¨ç¤ºç™¼ç¾äº†å¼•ç”¨
                        c. **å‹•æ…‹å¼•ç”¨è§£æ**: å°æ¯å€‹ç™¼ç¾çš„å¼•ç”¨ï¼š
                            - ä½¿ç”¨ `reference_location_lookup` åœ¨ç›®éŒ„ä¸­æŸ¥æ‰¾å°æ‡‰é é¢
                            - å¦‚æœæ‰¾åˆ°æ–°é é¢ï¼Œä½¿ç”¨ `pdf_page_extraction` æå–é€™äº›é é¢
                            - é‡æ–°åŸ·è¡Œè©²æ¨¡å‹çš„æ•¸æ“šæå–ï¼ˆç¾åœ¨åŒ…å«æ›´å¤šé é¢ï¼‰
                        d. é‡è¤‡ç›´åˆ°è©²æ¨¡å‹çš„æ•¸æ“šå®Œæ•´ç‚ºæ­¢
                    5. **æ•¸æ“šé©—è­‰**: é©—è­‰æ‰€æœ‰æå–çš„æ•¸æ“šã€‚

                    **é—œéµé‚è¼¯**ï¼š
                    - åªæœ‰åœ¨å¯¦éš›æå–æ•¸æ“šæ™‚ç™¼ç¾å¼•ç”¨ï¼Œæ‰å»æŸ¥æ‰¾å’Œæå–é¡å¤–é é¢
                    - æ¯å€‹è²¡å‹™æ¨¡å‹éƒ½å¯èƒ½è§¸ç™¼è‡ªå·±çš„é é¢æ“´å±•
                    - ç¢ºä¿æ•¸æ“šå®Œæ•´æ€§ï¼Œé¿å…éºæ¼é‡è¦çš„é™„è¨»æˆ–æ˜ç´°

                    è«‹åœ¨æ¯ä¸€æ­¥éƒ½æä¾›è©³ç´°çš„é€²åº¦å ±å‘Šã€‚æœ€çµ‚ç›®æ¨™æ˜¯æå–å‡ºæº–ç¢ºã€å®Œæ•´çš„è²¡å‹™æ•¸æ“šã€‚
                    å›ç­”è«‹ä½¿ç”¨ç¹é«”ä¸­æ–‡ã€‚""",
                ),
                ("user", "{input}"),
                MessagesPlaceholder(variable_name="agent_scratchpad"),
            ]
        )

        agent = create_openai_functions_agent(
            self.llm,
            self.tools,
            prompt,
        )

        custom_callback = CustomLogCallbackHandler()
        callbacks = [custom_callback]

        return AgentExecutor(
            agent=agent, tools=self.tools, verbose=False, callbacks=callbacks
        )

    def _setup_genai_client(self):
        api_key = os.getenv("GEMINI_API_KEY")
        if not api_key:
            raise ValueError("è«‹è¨­å®š GEMINI_API_KEY ç’°å¢ƒè®Šæ•¸")
        return Client(api_key=api_key)

    def analyze_financial_report(self, pdf_path: str) -> Dict[str, Any]:
        """
        åˆ†æè²¡å‹™å ±è¡¨çš„ä¸»è¦å…¥å£

        Args:
            pdf_path: PDF æª”æ¡ˆè·¯å¾‘

        Returns:
            åˆ†æçµæœå­—å…¸
        """
        self.state = PDFProcessingState(pdf_path=pdf_path)
        self.tools = self._setup_tools(self.state)
        self.agent = self._setup_agent()

        task = f"""
        è«‹åˆ†æé€™å€‹è²¡å‹™å ±è¡¨ PDF æª”æ¡ˆï¼š{pdf_path}

        è«‹æŒ‰ç…§ä»¥ä¸‹æ­¥é©Ÿé€²è¡Œï¼š

        1.  **æå–å‰ 5 é **ä»¥é€²è¡Œåˆæ­¥åˆ†æå’Œç›®éŒ„æª¢æ¸¬ã€‚
        2.  **åˆ†æç›®éŒ„**ï¼Œæ‰¾å‡ºæ‰€æœ‰ä¸»è¦è²¡å‹™å ±è¡¨ï¼ˆå€‹é«”è³‡ç”¢è² å‚µè¡¨ã€å€‹é«”ç¶œåˆæç›Šè¡¨ã€å€‹é«”æ¬Šç›Šè®Šå‹•è¡¨ã€å€‹é«”ç¾é‡‘æµé‡è¡¨ã€é‡è¦æœƒè¨ˆé …ç›®æ˜ç´°è¡¨ï¼‰çš„é é¢ä½ç½®ã€‚
        3.  **æå–æ‰€æœ‰å·²è­˜åˆ¥çš„è²¡å‹™å ±è¡¨é é¢**ã€‚
        4.  **æª¢æ¸¬é é¢ä¸­çš„äº¤å‰å¼•ç”¨**ã€‚å¦‚æœ `reference_detection` å·¥å…·çš„å›æ‡‰ä¸­ `additional_pages_needed` åˆ—è¡¨ä¸ç‚ºç©ºï¼Œå‰‡ **ç«‹å³ä½¿ç”¨ `pdf_page_extraction` å·¥å…·æå–é€™äº›é¡å¤–é é¢**ï¼Œç„¶å¾Œå†é€²è¡Œä¸‹ä¸€æ­¥ã€‚ç¢ºä¿æ‰€æœ‰é€™äº›é é¢éƒ½å·²åŒ…å«åœ¨ Agent çš„ç‹€æ…‹ä¸­ã€‚
        5.  å°æ¯å€‹è²¡å‹™æ¨¡å‹æå–æ•¸æ“šï¼š
            - ç¾é‡‘åŠç´„ç•¶ç¾é‡‘
            - é ä»˜æ¬¾é …
            - æ‡‰æ”¶é—œä¿‚äººæ¬¾é …
            - è² å‚µç¸½é¡
        6.  é©—è­‰æå–çš„æ•¸æ“šæº–ç¢ºæ€§ã€‚

        è«‹åœ¨æ¯ä¸€æ­¥éƒ½æä¾›è©³ç´°çš„é€²åº¦å ±å‘Šï¼Œä¸¦åœ¨æœ€å¾Œå½™ç¸½æ‰€æœ‰æå–çš„è²¡å‹™æ•¸æ“šã€‚
        """

        try:
            if not self.agent:
                raise RuntimeError("Agent not initialized. This should not happen.")
            result = self.agent.invoke({"input": task})
            return {
                "success": True,
                "result": result,
                "state": self.state.model_dump() if self.state else None,
            }
        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "state": self.state.model_dump() if self.state else None,
            }


# ===============================
# ä½¿ç”¨ç¯„ä¾‹
# ===============================


def main():
    """ä¸»å‡½æ•¸"""
    print("ğŸš€ å•Ÿå‹•åŸºæ–¼ LangChain çš„è²¡å‹™å ±è¡¨åˆ†æ Agent")

    # åˆå§‹åŒ– Agent
    agent = FinancialReportAnalysisAgent()

    # åˆ†æè²¡å‹™å ±è¡¨
    pdf_path = "assets\pdfs\quartely-results-2024-zh_tcm27-94407.pdf"
    print(f"ğŸ“„ é–‹å§‹åˆ†æï¼š{pdf_path}")

    result = agent.analyze_financial_report(pdf_path)

    if result["success"]:
        print("âœ… åˆ†æå®Œæˆ")
        print(f"çµæœï¼š{result['result']}")
    else:
        print("âŒ åˆ†æå¤±æ•—")
        print(f"éŒ¯èª¤ï¼š{result['error']}")


if __name__ == "__main__":
    main()
